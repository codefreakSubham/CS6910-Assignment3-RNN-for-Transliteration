{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Useful Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport cv2\nimport pathlib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-24T11:41:02.938080Z","iopub.execute_input":"2022-04-24T11:41:02.938416Z","iopub.status.idle":"2022-04-24T11:41:03.171223Z","shell.execute_reply.started":"2022-04-24T11:41:02.938318Z","shell.execute_reply":"2022-04-24T11:41:03.170360Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Downloading the Dakshina dataset","metadata":{}},{"cell_type":"code","source":"#Downloading\n!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n    \n#Uncompressing\n!tar -xf dakshina_dataset_v1.0.tar","metadata":{"execution":{"iopub.status.busy":"2022-04-24T11:41:03.172562Z","iopub.execute_input":"2022-04-24T11:41:03.172755Z","iopub.status.idle":"2022-04-24T11:41:31.830599Z","shell.execute_reply.started":"2022-04-24T11:41:03.172731Z","shell.execute_reply":"2022-04-24T11:41:31.829734Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Pre processing data","metadata":{}},{"cell_type":"code","source":"def read(data_path, characters = False):\n    \n    # Returns the (x, y) pair from the dataset\n    # If characters == True, the input/output sample would be in the form list of characters, else as string\n\n    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n        lines = [line.split(\"\\t\") for line in f.read().split(\"\\n\") if line != '']\n    \n    x, y = [val[1] for val in lines], [val[0] for val in lines]\n    '''if characters:\n        input, target = [list(inp_str) for inp_str in input], [list(tar_str) for tar_str in target]'''\n    return x, y","metadata":{"execution":{"iopub.status.busy":"2022-04-24T11:49:17.587168Z","iopub.execute_input":"2022-04-24T11:49:17.587477Z","iopub.status.idle":"2022-04-24T11:49:17.594064Z","shell.execute_reply.started":"2022-04-24T11:49:17.587446Z","shell.execute_reply":"2022-04-24T11:49:17.593156Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"START_CHAR = '\\t'\nEND_CHAR = '\\n'\nBLANK_CHAR = ' '\ndef encode_decode_characters(train_input, train_target, val_input, val_target):\n    \n    # Returns the encoding for characters to integer (as a dictionary) and decoding for integers to characters (as a list) for input and target data\n    # Encoding and decoding of input vocabulary\n    \n    input_char_enc = {}\n    input_char_dec = []\n    max_encoder_seq_length = 1\n    for string in train_input + val_input:\n        max_encoder_seq_length = max(max_encoder_seq_length, len(string))\n        for char in string:\n            if char not in input_char_enc:\n                input_char_enc[char] = len(input_char_dec)\n                input_char_dec.append(char)\n    if BLANK_CHAR not in input_char_enc:\n        input_char_enc[BLANK_CHAR] = len(input_char_dec)\n        input_char_dec.append(BLANK_CHAR)\n        \n    # Encoding and decoding of target vocabulary\n    target_char_enc = {}\n    target_char_dec = []\n    target_char_enc[START_CHAR] = len(target_char_dec)\n    target_char_dec.append(START_CHAR)\n    max_decoder_seq_length = 1\n    for string in train_target + val_target:\n        max_decoder_seq_length = max(max_decoder_seq_length, len(string)+2)\n        for char in string:\n            if char not in target_char_enc:\n                target_char_enc[char] = len(target_char_dec)\n                target_char_dec.append(char)\n    target_char_enc[END_CHAR] = len(target_char_dec)\n    target_char_dec.append(END_CHAR)\n    if ' ' not in target_char_enc:\n        target_char_enc[BLANK_CHAR] = len(target_char_dec)\n        target_char_dec.append(BLANK_CHAR)\n\n    print(\"Number of training samples:\", len(train_input))\n    print(\"Number of validation samples:\", len(val_input))\n    print(\"Number of unique input tokens:\", len(input_char_dec))\n    print(\"Number of unique output tokens:\", len(target_char_dec))\n    print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n    print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n\n    return input_char_enc, input_char_dec, target_char_enc, target_char_dec, max_encoder_seq_length, max_decoder_seq_length","metadata":{"execution":{"iopub.status.busy":"2022-04-24T11:50:13.890175Z","iopub.execute_input":"2022-04-24T11:50:13.890816Z","iopub.status.idle":"2022-04-24T11:50:13.900695Z","shell.execute_reply.started":"2022-04-24T11:50:13.890761Z","shell.execute_reply":"2022-04-24T11:50:13.899699Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def process_data(input, enc_timesteps, input_char_enc, target = None, dec_timesteps = None, target_char_enc = None):\n    \n    # Returns the input and target data in a form needed by the Keras embedding layer (i.e) \n    # decoder_input & encoder_input -- (None, timesteps) where each character is encoded by an integer\n    # decoder_output -- (None, timesteps, vocabulary size) where the last dimension is the one-hot encoding\n    # BLANK_CHAR -- space (equivalent to no meaningful input / blank input)\n    \n    encoder_input = np.array([[input_char_enc[ch] for ch in string] + [input_char_enc[BLANK_CHAR]] * (enc_timesteps - len(string)) for string in input])\n\n    decoder_input, decoder_target = None, None\n    if target is not None and dec_timesteps is not None and target_char_enc is not None:\n        \n        # START_CHAR -- start of sequence, END_CHAR -- end of sequence\n        decoder_input = np.array([[target_char_enc[START_CHAR]] + [target_char_enc[ch] for ch in string] + [target_char_enc[END_CHAR]] \n                                    + [target_char_enc[BLANK_CHAR]] * (dec_timesteps - len(string) - 2) for string in target])\n        decoder_target = np.zeros((decoder_input.shape[0], dec_timesteps, len(target_char_enc)), dtype='float32')\n\n        for i in range(decoder_input.shape[0]):\n            for t, char_ind in enumerate(decoder_input[i]):\n                if t > 0:\n                    decoder_target[i,t-1,char_ind] = 1.0\n            decoder_target[i,t:,target_char_enc[BLANK_CHAR]] = 1.0\n\n    return encoder_input, decoder_input, decoder_target","metadata":{"execution":{"iopub.status.busy":"2022-04-24T12:19:30.801337Z","iopub.execute_input":"2022-04-24T12:19:30.801689Z","iopub.status.idle":"2022-04-24T12:19:30.813214Z","shell.execute_reply.started":"2022-04-24T12:19:30.801659Z","shell.execute_reply":"2022-04-24T12:19:30.812225Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_x, train_y = read('./dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv')\nval_x, val_y = read('./dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv')\ntest_x, test_y = read('./dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv')'\n\n# Assigning encoding and decoding for input and target characters\ninput_char_enc, input_char_dec, target_char_enc, target_char_dec, max_encoder_seq_length, max_decoder_seq_length = encode_decode_characters(\n    train_x, train_y, val_x, val_y)\n\n# Assigning training, validation and test encoder input, decoder input, decoder output\ntrain_enc_x, train_dec_x, train_dec_y = process_data(train_inp, max_encoder_seq_length, input_char_enc, train_out, \n                                                                  max_decoder_seq_length, target_char_enc)\nval_enc_x, val_dec_x, val_dec_y = process_data(val_inp, max_encoder_seq_length, input_char_enc, val_out, \n                                                            max_decoder_seq_length, target_char_enc)\ntest_enc_x, test_dec_x, test_dec_y = process_data(test_inp, max_encoder_seq_length, input_char_enc, test_out, \n                                                               max_decoder_seq_length, target_char_enc)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T12:20:14.028072Z","iopub.execute_input":"2022-04-24T12:20:14.028415Z","iopub.status.idle":"2022-04-24T12:20:17.995595Z","shell.execute_reply.started":"2022-04-24T12:20:14.028385Z","shell.execute_reply":"2022-04-24T12:20:17.994672Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-04-24T12:28:30.209976Z","iopub.execute_input":"2022-04-24T12:28:30.211007Z","iopub.status.idle":"2022-04-24T12:28:30.217481Z","shell.execute_reply.started":"2022-04-24T12:28:30.210958Z","shell.execute_reply":"2022-04-24T12:28:30.216249Z"},"trusted":true},"execution_count":33,"outputs":[]}]}