{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Useful Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport cv2\nimport pathlib\nimport tensorflow as tf\nimport tensorflow.keras as keras","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-26T17:09:46.940320Z","iopub.execute_input":"2022-04-26T17:09:46.940676Z","iopub.status.idle":"2022-04-26T17:09:54.106289Z","shell.execute_reply.started":"2022-04-26T17:09:46.940586Z","shell.execute_reply":"2022-04-26T17:09:54.105178Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Downloading the Dakshina dataset","metadata":{}},{"cell_type":"code","source":"#Downloading\n!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n    \n#Uncompressing\n!tar -xf dakshina_dataset_v1.0.tar","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:09:54.108196Z","iopub.execute_input":"2022-04-26T17:09:54.108495Z","iopub.status.idle":"2022-04-26T17:10:12.798799Z","shell.execute_reply.started":"2022-04-26T17:09:54.108460Z","shell.execute_reply":"2022-04-26T17:10:12.794661Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Pre processing data","metadata":{}},{"cell_type":"code","source":"def read(data_path, characters = False):\n    \n    # Returns the (x, y) pair from the dataset\n    # If characters == True, the input/output sample would be in the form list of characters, else as string\n\n    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n        lines = [line.split(\"\\t\") for line in f.read().split(\"\\n\") if line != '']\n    \n    x, y = [val[1] for val in lines], [val[0] for val in lines]\n    '''if characters:\n        input, target = [list(inp_str) for inp_str in input], [list(tar_str) for tar_str in target]'''\n    return x, y","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:10:12.806507Z","iopub.execute_input":"2022-04-26T17:10:12.807694Z","iopub.status.idle":"2022-04-26T17:10:12.826463Z","shell.execute_reply.started":"2022-04-26T17:10:12.807613Z","shell.execute_reply":"2022-04-26T17:10:12.825526Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"START_CHAR = '\\t'\nEND_CHAR = '\\n'\nBLANK_CHAR = ' '\ndef encode_decode_characters(train_input, train_target, val_input, val_target):\n    \n    # Returns the encoding for characters to integer (as a dictionary) and decoding for integers to characters (as a list) for input and target data\n    # Encoding and decoding of input vocabulary\n    \n    input_char_enc = {}\n    input_char_dec = []\n    max_encoder_seq_length = 1\n    for string in train_input + val_input:\n        max_encoder_seq_length = max(max_encoder_seq_length, len(string))\n        for char in string:\n            if char not in input_char_enc:\n                input_char_enc[char] = len(input_char_dec)\n                input_char_dec.append(char)\n    if BLANK_CHAR not in input_char_enc:\n        input_char_enc[BLANK_CHAR] = len(input_char_dec)\n        input_char_dec.append(BLANK_CHAR)\n        \n    # Encoding and decoding of target vocabulary\n    target_char_enc = {}\n    target_char_dec = []\n    target_char_enc[START_CHAR] = len(target_char_dec)\n    target_char_dec.append(START_CHAR)\n    max_decoder_seq_length = 1\n    for string in train_target + val_target:\n        max_decoder_seq_length = max(max_decoder_seq_length, len(string)+2)\n        for char in string:\n            if char not in target_char_enc:\n                target_char_enc[char] = len(target_char_dec)\n                target_char_dec.append(char)\n    target_char_enc[END_CHAR] = len(target_char_dec)\n    target_char_dec.append(END_CHAR)\n    if ' ' not in target_char_enc:\n        target_char_enc[BLANK_CHAR] = len(target_char_dec)\n        target_char_dec.append(BLANK_CHAR)\n\n    print(\"Number of training samples:\", len(train_input))\n    print(\"Number of validation samples:\", len(val_input))\n    print(\"Number of unique input tokens:\", len(input_char_dec))\n    print(\"Number of unique output tokens:\", len(target_char_dec))\n    print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n    print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n\n    return input_char_enc, input_char_dec, target_char_enc, target_char_dec, max_encoder_seq_length, max_decoder_seq_length","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:10:12.831244Z","iopub.execute_input":"2022-04-26T17:10:12.832022Z","iopub.status.idle":"2022-04-26T17:10:17.729363Z","shell.execute_reply.started":"2022-04-26T17:10:12.831955Z","shell.execute_reply":"2022-04-26T17:10:17.728031Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def process_data(input, enc_timesteps, input_char_enc, target = None, dec_timesteps = None, target_char_enc = None):\n    \n    # Returns the input and target data in a form needed by the Keras embedding layer (i.e) \n    # decoder_input & encoder_input -- (None, timesteps) where each character is encoded by an integer\n    # decoder_output -- (None, timesteps, vocabulary size) where the last dimension is the one-hot encoding\n    # BLANK_CHAR -- space (equivalent to no meaningful input / blank input)\n    \n    encoder_input = np.array([[input_char_enc[ch] for ch in string] + [input_char_enc[BLANK_CHAR]] * (enc_timesteps - len(string)) for string in input])\n\n    decoder_input, decoder_target = None, None\n    if target is not None and dec_timesteps is not None and target_char_enc is not None:\n        \n        # START_CHAR -- start of sequence, END_CHAR -- end of sequence\n        decoder_input = np.array([[target_char_enc[START_CHAR]] + [target_char_enc[ch] for ch in string] + [target_char_enc[END_CHAR]] \n                                    + [target_char_enc[BLANK_CHAR]] * (dec_timesteps - len(string) - 2) for string in target])\n        decoder_target = np.zeros((decoder_input.shape[0], dec_timesteps, len(target_char_enc)), dtype='float32')\n\n        for i in range(decoder_input.shape[0]):\n            for t, char_ind in enumerate(decoder_input[i]):\n                if t > 0:\n                    decoder_target[i,t-1,char_ind] = 1.0\n            decoder_target[i,t:,target_char_enc[BLANK_CHAR]] = 1.0\n\n    return encoder_input, decoder_input, decoder_target","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:10:17.733819Z","iopub.execute_input":"2022-04-26T17:10:17.737452Z","iopub.status.idle":"2022-04-26T17:10:17.753372Z","shell.execute_reply.started":"2022-04-26T17:10:17.737388Z","shell.execute_reply":"2022-04-26T17:10:17.752495Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_x, train_y = read('./dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv')\nval_x, val_y = read('./dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv')\ntest_x, test_y = read('./dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv')\n\n# Assigning encoding and decoding for input and target characters\ninput_char_enc, input_char_dec, target_char_enc, target_char_dec, max_encoder_seq_length, max_decoder_seq_length = encode_decode_characters(\n    train_x, train_y, val_x, val_y)\n\n# Assigning training, validation and test encoder input, decoder input, decoder output\ntrain_enc_x, train_dec_x, train_dec_y = process_data(train_x, max_encoder_seq_length, input_char_enc, train_y, \n                                                                  max_decoder_seq_length, target_char_enc)\nval_enc_x, val_dec_x, val_dec_y = process_data(val_x, max_encoder_seq_length, input_char_enc, val_y, \n                                                            max_decoder_seq_length, target_char_enc)\ntest_enc_x, test_dec_x, test_dec_y = process_data(test_x, max_encoder_seq_length, input_char_enc, test_y, \n                                                               max_decoder_seq_length, target_char_enc)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:13:36.714416Z","iopub.execute_input":"2022-04-26T17:13:36.714751Z","iopub.status.idle":"2022-04-26T17:13:42.041508Z","shell.execute_reply.started":"2022-04-26T17:13:36.714717Z","shell.execute_reply":"2022-04-26T17:13:42.040680Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Seq2Seq Model (without Attention)","metadata":{}},{"cell_type":"code","source":"def build_model(encoder_vocab_size, decoder_vocab_size, inp_emb_size=64, n_enc_layers=1, n_dec_layers=1, \n                 h_layer_size=64, cell_type='LSTM', dropout=0, r_dropout=0, cell_activation='tanh'):\n   \n    '''\n    Function to create a seq2seq model without attention.\n    Input :\n        encoder_vocab_size -- number of characters in input vocabulary (int)\n        decoder_vocab_size -- number of characters in output vocabulary (int)\n        inp_emb_size -- size of input embedding layer for encoder and decoder (int, default value : 64)\n        n_enc_layers -- number of layers of cell to stack in encoder (int, default value : 1)\n        n_dec_layers -- number of layers of cell to stack in decoder (int, default value : 1)\n        h_layer_size -- size of hidden layer of the encoder and decoder cells (int, default : 64)\n        cell_type -- type of cell used in encoder and decoder (string('LSTM'/ 'GRU'/ 'RNN'), default : 'LSTM')\n        dropout -- value of normal dropout (float(between 0 and 1), default : 0.0)\n        r_dropout -- value of recurrent dropout (float(between 0 and 1), default : 0.0)\n        cell_activation -- type of activation used in the cell (string, default : 'tanh')\n    Output :\n        model -- (Keras model object)\n    '''\n    \n    # Dictionary of different cell type\n    cell_dict = {\n        'RNN': keras.layers.SimpleRNN,\n        'GRU': keras.layers.GRU,\n        'LSTM': keras.layers.LSTM\n    }\n    \n    # Encoder input and embedding\n    encoder_input = keras.layers.Input(shape=(None,), name=\"input_1\")\n    encoder_inp_emb = keras.layers.Embedding(encoder_vocab_size, inp_emb_size, name=\"embedding_1\")(encoder_input)\n    \n    # Encoder cell layers\n    encoder_seq, *encoder_state = cell_dict[cell_type](h_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n                                                      dropout=dropout, recurrent_dropout=r_dropout, name=\"encoder_1\")(\n                                                            encoder_inp_emb\n                                                     )\n    for i in range(1, n_enc_layers):\n        encoder_seq, *encoder_state = cell_dict[cell_type](h_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n                                                          dropout=dropout, recurrent_dropout=r_dropout, name=\"encoder_\"+str(i+1))(\n                                                                encoder_seq\n                                                         )\n    \n    # Decoder input and embedding\n    decoder_input = keras.layers.Input(shape=(None,), name=\"input_2\")\n    decoder_inp_emb = keras.layers.Embedding(decoder_vocab_size, inp_emb_size, name=\"embedding_2\")(decoder_input)\n\n    # Decoder cell layers\n    decoder_seq, *_ = cell_dict[cell_type](h_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n                                          dropout=dropout, recurrent_dropout=r_dropout, name=\"decoder_1\")(\n                                                decoder_inp_emb, initial_state=encoder_state\n                                         )\n    for i in range(1, n_dec_layers):\n        decoder_seq, *_ = cell_dict[cell_type](h_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n                                              dropout=dropout, recurrent_dropout=r_dropout, name=\"decoder_\"+str(i+1))(\n                                                    decoder_seq, initial_state=encoder_state\n                                             )\n    \n    # Softmax Fully Connected dense layer\n    decoder_dense_output = keras.layers.Dense(decoder_vocab_size, activation=\"softmax\", name=\"dense_1\")(\n        decoder_seq\n    )\n\n    # Finally the full encoder-decoder model\n    model = keras.Model([encoder_input, decoder_input], decoder_dense_output)\n\n    model.summary(line_length=150)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:16:31.200715Z","iopub.execute_input":"2022-04-26T17:16:31.201275Z","iopub.status.idle":"2022-04-26T17:16:31.217314Z","shell.execute_reply.started":"2022-04-26T17:16:31.201237Z","shell.execute_reply":"2022-04-26T17:16:31.216638Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"build_model(len(input_char_dec), len(target_char_dec))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:16:34.372906Z","iopub.execute_input":"2022-04-26T17:16:34.373206Z","iopub.status.idle":"2022-04-26T17:16:34.984513Z","shell.execute_reply.started":"2022-04-26T17:16:34.373175Z","shell.execute_reply":"2022-04-26T17:16:34.983641Z"},"trusted":true},"execution_count":21,"outputs":[]}]}