{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Useful Imports\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport cv2\nimport pathlib\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.utils.vis_utils import plot_model\nimport csv\nfrom IPython.display import HTML as html_print\nfrom IPython.display import display\nimport wandb\nfrom wandb.keras import WandbCallback","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-02T18:21:46.457170Z","iopub.execute_input":"2022-05-02T18:21:46.457841Z","iopub.status.idle":"2022-05-02T18:21:46.464471Z","shell.execute_reply.started":"2022-05-02T18:21:46.457800Z","shell.execute_reply":"2022-05-02T18:21:46.463553Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"if os.path.exists('best_model_attn.h5'):\n    os.remove('best_model_attn.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:21:46.547618Z","iopub.execute_input":"2022-05-02T18:21:46.547937Z","iopub.status.idle":"2022-05-02T18:21:49.086325Z","shell.execute_reply.started":"2022-05-02T18:21:46.547898Z","shell.execute_reply":"2022-05-02T18:21:49.085309Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Downloading the Dakshina dataset","metadata":{}},{"cell_type":"code","source":"#Downloading\n!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n    \n#Uncompressing\n!tar -xf dakshina_dataset_v1.0.tar","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:21:49.088306Z","iopub.execute_input":"2022-05-02T18:21:49.088607Z","iopub.status.idle":"2022-05-02T18:22:06.068363Z","shell.execute_reply.started":"2022-05-02T18:21:49.088567Z","shell.execute_reply":"2022-05-02T18:22:06.067523Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Pre processing data","metadata":{}},{"cell_type":"code","source":"def read(data_path, characters = False):\n    \n    # Returns the (x, y) pair from the dataset\n    # If characters == True, the input/output sample would be in the form list of characters, else as string\n\n    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n        lines = [line.split(\"\\t\") for line in f.read().split(\"\\n\") if line != '']\n    \n    x, y = [val[1] for val in lines], [val[0] for val in lines]\n    '''if characters:\n        input, target = [list(inp_str) for inp_str in input], [list(tar_str) for tar_str in target]'''\n    return x, y","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:06.070277Z","iopub.execute_input":"2022-05-02T18:22:06.070581Z","iopub.status.idle":"2022-05-02T18:22:06.077947Z","shell.execute_reply.started":"2022-05-02T18:22:06.070540Z","shell.execute_reply":"2022-05-02T18:22:06.077177Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"START_CHAR = '\\t'\nEND_CHAR = '\\n'\nBLANK_CHAR = ' '\ndef encode_decode_characters(train_input, train_target, val_input, val_target):\n    \n    # Returns the encoding for characters to integer (as a dictionary) and decoding for integers to characters (as a list) for input and target data\n    # Encoding and decoding of input vocabulary\n    \n    input_char_enc = {}\n    input_char_dec = []\n    max_encoder_seq_length = 1\n    for string in train_input + val_input:\n        max_encoder_seq_length = max(max_encoder_seq_length, len(string))\n        for char in string:\n            if char not in input_char_enc:\n                input_char_enc[char] = len(input_char_dec)\n                input_char_dec.append(char)\n    if BLANK_CHAR not in input_char_enc:\n        input_char_enc[BLANK_CHAR] = len(input_char_dec)\n        input_char_dec.append(BLANK_CHAR)\n        \n    # Encoding and decoding of target vocabulary\n    target_char_enc = {}\n    target_char_dec = []\n    target_char_enc[START_CHAR] = len(target_char_dec)\n    target_char_dec.append(START_CHAR)\n    max_decoder_seq_length = 1\n    for string in train_target + val_target:\n        max_decoder_seq_length = max(max_decoder_seq_length, len(string)+2)\n        for char in string:\n            if char not in target_char_enc:\n                target_char_enc[char] = len(target_char_dec)\n                target_char_dec.append(char)\n    target_char_enc[END_CHAR] = len(target_char_dec)\n    target_char_dec.append(END_CHAR)\n    if ' ' not in target_char_enc:\n        target_char_enc[BLANK_CHAR] = len(target_char_dec)\n        target_char_dec.append(BLANK_CHAR)\n\n    print(\"Number of training samples:\", len(train_input))\n    print(\"Number of validation samples:\", len(val_input))\n    print(\"Number of unique input tokens:\", len(input_char_dec))\n    print(\"Number of unique output tokens:\", len(target_char_dec))\n    print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n    print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n\n    return input_char_enc, input_char_dec, target_char_enc, target_char_dec, max_encoder_seq_length, max_decoder_seq_length","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:06.079844Z","iopub.execute_input":"2022-05-02T18:22:06.080025Z","iopub.status.idle":"2022-05-02T18:22:07.413662Z","shell.execute_reply.started":"2022-05-02T18:22:06.080002Z","shell.execute_reply":"2022-05-02T18:22:07.412807Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def process_data(input, enc_timesteps, input_char_enc, target = None, dec_timesteps = None, target_char_enc = None):\n    \n    # Returns the input and target data in a form needed by the Keras embedding layer (i.e) \n    # decoder_input & encoder_input -- (None, timesteps) where each character is encoded by an integer\n    # decoder_output -- (None, timesteps, vocabulary size) where the last dimension is the one-hot encoding\n    # BLANK_CHAR -- space (equivalent to no meaningful input / blank input)\n    \n    encoder_input = np.array([[input_char_enc[ch] for ch in string] + [input_char_enc[BLANK_CHAR]] * (enc_timesteps - len(string)) for string in input])\n\n    decoder_input, decoder_target = None, None\n    if target is not None and dec_timesteps is not None and target_char_enc is not None:\n        \n        # START_CHAR -- start of sequence, END_CHAR -- end of sequence\n        decoder_input = np.array([[target_char_enc[START_CHAR]] + [target_char_enc[ch] for ch in string] + [target_char_enc[END_CHAR]] \n                                    + [target_char_enc[BLANK_CHAR]] * (dec_timesteps - len(string) - 2) for string in target])\n        decoder_target = np.zeros((decoder_input.shape[0], dec_timesteps, len(target_char_enc)), dtype='float32')\n\n        for i in range(decoder_input.shape[0]):\n            for t, char_ind in enumerate(decoder_input[i]):\n                if t > 0:\n                    decoder_target[i,t-1,char_ind] = 1.0\n            decoder_target[i,t:,target_char_enc[BLANK_CHAR]] = 1.0\n\n    return encoder_input, decoder_input, decoder_target","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:07.416425Z","iopub.execute_input":"2022-05-02T18:22:07.417822Z","iopub.status.idle":"2022-05-02T18:22:09.215604Z","shell.execute_reply.started":"2022-05-02T18:22:07.417781Z","shell.execute_reply":"2022-05-02T18:22:09.214865Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_x, train_y = read('./dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv')\nval_x, val_y = read('./dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv')\ntest_x, test_y = read('./dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv')\n\n# Assigning encoding and decoding for input and target characters\ninput_char_enc, input_char_dec, target_char_enc, target_char_dec, max_encoder_seq_length, max_decoder_seq_length = encode_decode_characters(\n    train_x, train_y, val_x, val_y)\n\n# Assigning training, validation and test encoder input, decoder input, decoder output\ntrain_enc_x, train_dec_x, train_dec_y = process_data(train_x, max_encoder_seq_length, input_char_enc, train_y, \n                                                                  max_decoder_seq_length, target_char_enc)\nval_enc_x, val_dec_x, val_dec_y = process_data(val_x, max_encoder_seq_length, input_char_enc, val_y, \n                                                            max_decoder_seq_length, target_char_enc)\ntest_enc_x, test_dec_x, test_dec_y = process_data(test_x, max_encoder_seq_length, input_char_enc, test_y, \n                                                               max_decoder_seq_length, target_char_enc)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:09.218150Z","iopub.execute_input":"2022-05-02T18:22:09.219024Z","iopub.status.idle":"2022-05-02T18:22:16.264401Z","shell.execute_reply.started":"2022-05-02T18:22:09.218987Z","shell.execute_reply":"2022-05-02T18:22:16.263687Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def convert_to_word(predictions, char_enc, char_dec = None):\n    # Function to return the predictions after cutting the END_CHAR and BLANK_CHAR s at the end.\n    # If char_dec == None, the predictions are in the form of decoded string, otherwise as list of integers\n    no_samples = len(predictions) if type(predictions) is list else predictions.shape[0]\n    pred_words = ['' for _ in range(no_samples)]\n    for i, pred_list in enumerate(predictions):\n        for l in pred_list:\n            # Stop word : END_CHAR\n            if l == char_enc[END_CHAR]:\n                break\n            pred_words[i] += char_dec[l] if char_dec is not None else l\n    \n    return pred_words","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.265572Z","iopub.execute_input":"2022-05-02T18:22:16.265841Z","iopub.status.idle":"2022-05-02T18:22:16.274101Z","shell.execute_reply.started":"2022-05-02T18:22:16.265808Z","shell.execute_reply":"2022-05-02T18:22:16.273333Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Seq2Seq Model (with Attention)","metadata":{}},{"cell_type":"markdown","source":"### Creating Attention layer","metadata":{}},{"cell_type":"code","source":"from keras.layers import Layer\nimport keras.backend as K\n\nclass AttentionLayer(Layer):\n    \"\"\"\n    Source referenced : https://github.com/thushv89/attention_keras/blob/master/src/layers/attention.py\n    W_a, U_a, and V_a - 3 sets of weights\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super(AttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert isinstance(input_shape, list)\n        # Create a trainable weight variable for this layer.\n\n        self.W_a = self.add_weight(name='W_a',\n                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.U_a = self.add_weight(name='U_a',\n                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.V_a = self.add_weight(name='V_a',\n                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n                                   initializer='uniform',\n                                   trainable=True)\n\n        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, inputs, verbose=False):\n        \"\"\"\n        inputs: [encoder_output_sequence, decoder_output_sequence]\n        \"\"\"\n        assert type(inputs) == list\n        encoder_out_seq, decoder_out_seq = inputs\n        if verbose:\n            print('encoder_out_seq>', encoder_out_seq.shape)\n            print('decoder_out_seq>', decoder_out_seq.shape)\n\n        def energy_step(inputs, states):\n            \n            \"\"\" Step function for computing energy for a single decoder state\n            inputs: (batchsize * 1 * de_in_dim)\n            states: (batchsize * 1 * de_latent_dim)\n            \"\"\"\n\n            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n\n            \"\"\" Some parameters required for shaping tensors\"\"\"\n            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n            de_hidden = inputs.shape[-1]\n\n            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n            # <= batch size * en_seq_len * latent_dim\n            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n\n            \"\"\" Computing hj.Ua \"\"\"\n            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n            if verbose:\n                print('Ua.h>', U_a_dot_h.shape)\n\n            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n            # <= batch_size*en_seq_len, latent_dim\n            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n            if verbose:\n                print('Ws+Uh>', Ws_plus_Uh.shape)\n\n            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n            # <= batch_size, en_seq_len\n            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n            # <= batch_size, en_seq_len\n            e_i = K.softmax(e_i)\n\n            if verbose:\n                print('ei>', e_i.shape)\n\n            return e_i, [e_i]\n\n        def context_step(inputs, states):\n            \"\"\" Step function for computing ci using ei \"\"\"\n\n            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n\n            # <= batch_size, hidden_size\n            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n            if verbose:\n                print('ci>', c_i.shape)\n            return c_i, [c_i]\n\n        fake_state_c = K.sum(encoder_out_seq, axis=1)\n        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n\n        \"\"\" Computing energy outputs \"\"\"\n        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n        last_out, e_outputs, _ = K.rnn(\n            energy_step, decoder_out_seq, [fake_state_e],\n        )\n\n        \"\"\" Computing context vectors \"\"\"\n        last_out, c_outputs, _ = K.rnn(\n            context_step, e_outputs, [fake_state_c],\n        )\n\n        return c_outputs, e_outputs\n\n    def compute_output_shape(self, input_shape):\n        \"\"\" Outputs produced by the layer \"\"\"\n        return [\n            # (batch_size, decoder_timesteps, decoder_h_layer_size)\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n            # (batch_size, decoder_timesteps, encoder_timesteps)\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n        ]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.275860Z","iopub.execute_input":"2022-05-02T18:22:16.276546Z","iopub.status.idle":"2022-05-02T18:22:16.296990Z","shell.execute_reply.started":"2022-05-02T18:22:16.276499Z","shell.execute_reply":"2022-05-02T18:22:16.296335Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Building the model","metadata":{}},{"cell_type":"code","source":"def build_model(encoder_vocab_size, decoder_vocab_size, inp_emb_size=64, n_enc_layers=1, n_dec_layers=1, \n                           h_layer_size=64, cell_type='LSTM', dropout=0, r_dropout=0, cell_activation='tanh'):\n    '''\n    Function to create a seq2seq model without attention.\n    Input :\n        encoder_vocab_size -- number of characters in input vocabulary (int)\n        decoder_vocab_size -- number of characters in output vocabulary (int)\n        inp_emb_size -- size of input embedding layer for encoder and decoder (int, default value : 64)\n        n_enc_layers -- number of layers of cell to stack in encoder (int, default value : 1)\n        n_dec_layers -- number of layers of cell to stack in decoder (int, default value : 1)\n        h_layer_size -- size of hidden layer of the encoder and decoder cells (int, default : 64)\n        cell_type -- type of cell used in encoder and decoder (string('LSTM'/ 'GRU'/ 'RNN'), default : 'LSTM')\n        dropout -- value of normal dropout (float(between 0 and 1), default : 0.0)\n        r_dropout -- value of recurrent dropout (float(between 0 and 1), default : 0.0)\n        cell_activation -- type of activation used in the cell (string, default : 'tanh')\n    Output :\n        model -- (Keras model object)\n    '''\n    \n    # Getting cell type\n    get_cell = {\n        'RNN': keras.layers.SimpleRNN,\n        'GRU': keras.layers.GRU,\n        'LSTM': keras.layers.LSTM\n    }\n    # Encoder input and embedding\n    encoder_input = keras.layers.Input(shape=(None,), name=\"input_1\")\n    encoder_inp_emb = keras.layers.Embedding(encoder_vocab_size, inp_emb_size, name=\"embedding_1\")(encoder_input)\n\n    # Encoder cell layers\n    encoder_seq, *encoder_state = get_cell[cell_type](h_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n                                                      dropout=dropout, recurrent_dropout=r_dropout, name=\"encoder_1\")(\n                                                            encoder_inp_emb\n                                                     )\n    for i in range(1, n_enc_layers):\n        encoder_seq, *encoder_state = get_cell[cell_type](h_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n                                                          dropout=dropout, recurrent_dropout=r_dropout, name=\"encoder_\"+str(i+1))(\n                                                                encoder_seq\n                                                         )\n    # Decoder input and embedding\n    decoder_input = keras.layers.Input(shape=(None,), name=\"input_2\")\n    decoder_inp_emb = keras.layers.Embedding(decoder_vocab_size, inp_emb_size, name=\"embedding_2\")(decoder_input)\n    decoder_seq = decoder_inp_emb\n    # Decoder cell layers\n    for i in range(n_dec_layers-1):\n        decoder_seq, *_ = get_cell[cell_type](h_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n                                              dropout=dropout, recurrent_dropout=r_dropout, name=\"decoder_\"+str(i+1))(\n                                                    decoder_seq, initial_state=encoder_state\n                                             )\n    # Decoder last layer\n    decoder_seq, *_ = get_cell[cell_type](h_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n                                          dropout=dropout, recurrent_dropout=r_dropout, name=\"decoder_1\")(\n                                                decoder_inp_emb, initial_state=encoder_state\n                                         )\n\n    # Attention layer\n    attn_out, attn_scores = AttentionLayer(name='attention_1')([encoder_seq, decoder_seq])        # Bahdanau Attention\n    # Concat attention output and decoder output\n    dense_concat_input = keras.layers.Concatenate(axis=-1, name='concat_layer_1')([decoder_seq, attn_out])\n\n    # Time distributed Softmax FC layer\n    decoder_dense_layer = keras.layers.Dense(decoder_vocab_size, activation=\"softmax\", name=\"dense_1\")\n    decoder_dense_output = decoder_dense_layer(dense_concat_input)\n\n    # Define the model that will turn encoder_input_data and decoder_input_data into decoder_target_data\n    model = keras.Model([encoder_input, decoder_input], decoder_dense_output)\n\n    model.summary(line_length=150)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.299758Z","iopub.execute_input":"2022-05-02T18:22:16.299943Z","iopub.status.idle":"2022-05-02T18:22:16.317208Z","shell.execute_reply.started":"2022-05-02T18:22:16.299919Z","shell.execute_reply":"2022-05-02T18:22:16.316556Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Inference Model (with attention)","metadata":{}},{"cell_type":"code","source":"def create_attention_inference_model(model):\n    \n    '''\n    Function to return models needed for inference from the original model (without attention).\n    Inputs :\n        model -- non-attention model used for training\n    Outputs :\n        encoder_model \n        deocder_model\n        n_enc_layers -- number of layers in the encoder(int)\n        n_dec_layers -- number of layers in the decoder(int)\n    '''\n    \n    # Calculating number of layers in encoder and decoder\n    n_enc_layers, n_dec_layers = 0, 0\n    for layer in model.layers:\n        n_enc_layers += layer.name.startswith('encoder')\n        n_dec_layers += layer.name.startswith('decoder')\n\n    # Encoder input\n    encoder_input = model.input[0]      # Input_1\n    # Encoder cell final layer\n    encoder_cell = model.get_layer(\"encoder_\"+str(n_enc_layers))\n    encoder_type = encoder_cell.__class__.__name__\n    encoder_seq, *encoder_state = encoder_cell.output\n    # Encoder model\n    encoder_model = keras.Model(encoder_input, encoder_state)\n\n    # Decoder input\n    decoder_input = model.input[1]      # Input_2\n    decoder_inp_emb = model.get_layer(\"embedding_2\")(decoder_input)\n    decoder_seq = decoder_inp_emb\n    # Inputs to decoder layers' initial states\n    decoder_states, decoder_state_inputs = [], []\n    for i in range(1, n_dec_layers+1):\n        if encoder_type == 'LSTM':\n            decoder_state_input = [keras.Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(2*i+1)), \n                                   keras.Input(shape=(encoder_state[1].shape[1],), name=\"input_\"+str(2*i+2))]\n        else:\n            decoder_state_input = [keras.Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(i+2))]\n\n        decoder_cell = model.get_layer(\"decoder_\"+str(i))\n        decoder_seq, *decoder_state = decoder_cell(decoder_seq, initial_state=decoder_state_input)\n        decoder_states += decoder_state\n        decoder_state_inputs += decoder_state_input\n\n    # Attention layer\n    attn_out, attn_scores = model.get_layer('attention_1')([encoder_seq, decoder_seq])        # Bahdanau Attention\n    # Concat attention input and decoder output\n    dense_concat_input = keras.layers.Concatenate(axis=-1, name='concat_layer_1')([decoder_seq, attn_out])\n\n    # Softmax FC layer\n    decoder_dense = model.get_layer(\"dense_1\")\n    decoder_dense_output = decoder_dense(dense_concat_input)\n\n    # Decoder model\n    decoder_model = keras.Model(\n        [encoder_input, decoder_input] + decoder_state_inputs, [attn_scores, decoder_dense_output] + decoder_states\n    )\n\n    return encoder_model, decoder_model, n_enc_layers, n_dec_layers","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.321074Z","iopub.execute_input":"2022-05-02T18:22:16.321347Z","iopub.status.idle":"2022-05-02T18:22:16.336472Z","shell.execute_reply.started":"2022-05-02T18:22:16.321283Z","shell.execute_reply":"2022-05-02T18:22:16.335790Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Beam Decoder","metadata":{}},{"cell_type":"code","source":"def beam_decoder_infer(model, input_seqs, max_decoder_timesteps, K=1, target_seqs=None, starting_char_enc=0, batch_size=64, attention=True):\n    '''\n    Function to do inference on the model using beam decoder.\n    Inputs :\n        model -- training model\n        input_seqs -- input to encoder(numpy array, shape : (None, timesteps))\n        max_decoder_timesteps -- Number of timesteps to infer in decoder(int)\n        K -- beam width of beam decoder(int, default : 1)\n        target_seqs -- expected target(numpy array, shape : (None, timesteps, decoder_vocab_size), deault : None)\n                       If None, cross entropy errors won't be calculated.\n        starting_char_enc -- Encoding integer for START_CHAR(int, default : 0)\n        batch_size -- batch_size sent to Keras predict(int, default : 64)\n        attention -- whether the model has attention or not(bool, defualt : False)\n        \n    Outputs :\n        final_outputs -- top K output sequences(numpy array, shape : (None, K, timesteps))\n        final_errors -- cross entropy errors for top K output(numpy array, shape : (None, K))\n        states_values -- hidden states of decoder(numpy array, shape : (K, None, timesteps, h_layer_size))\n        final_attn_scores -- attention to all encoder timesteps for a decoder timestep(numpy array, shape : (None, K, decoder_timesteps, encoder_timesteps))\n    '''\n    \n    # Generating output from encoder\n    encoder_model, decoder_model, n_enc_layers, n_dec_layers = create_attention_inference_model(model)\n    encoder_output = encoder_model.predict(input_seqs, batch_size=batch_size)\n    encoder_out = encoder_output if type(encoder_output) is list else [encoder_output]\n\n    # Number of input samples in the data passed\n    no_samples = input_seqs.shape[0]\n\n    # Top K output sequences for each input \n    final_outputs = np.zeros((no_samples, K, max_decoder_timesteps), dtype=np.int32)\n    \n    # Errors for top K output sequences for each input\n    final_errors = np.zeros((no_samples, K))\n    \n    # Attention scores for top K output sequences for each input\n    final_attn_scores = np.zeros((no_samples, K, max_decoder_timesteps, input_seqs.shape[1]))\n\n    # decoder input sequence for 1 timestep (for all samples). Initially one choice only there\n    decoder_k_inputs = np.zeros((no_samples, 1, 1))\n    \n    # Populate the input sequence with the start character at the 1st timestep\n    decoder_k_inputs[:, :, 0] = starting_char_enc\n\n    # (log(probability) sequence, decoder output sequence) pairs for all choices and all samples. Probability starts with log(1) = 0\n    decoder_k_out = [[(0, [])] for _ in range(no_samples)]\n    \n    # Categorical cross entropy error in the sequence for all choice and all samples\n    errors = [[0] for _ in range(no_samples)]\n    \n    # Output states from decoder for all choices, and all samples\n    states_values  = [encoder_out * n_dec_layers]\n\n    # Attention weights output\n    attn_k_scores = [[None] for _ in range(no_samples)]\n\n    # Sampling loop\n    for it in range(max_decoder_timesteps):\n        # Storing respective data for all possibilities\n        All_k_beams = [[] for _ in range(no_samples)]\n        All_decoder_states = [[] for _ in range(no_samples)]\n        All_errors = [[] for _ in range(no_samples)]\n        All_attn_scores = [[] for _ in range(no_samples)]\n\n        for k in range(len(decoder_k_out[0])):\n            if attention:\n                attn_score, decoder_output, *decoder_states = decoder_model.predict([input_seqs, decoder_k_inputs[:,k]] + states_values[k], batch_size=batch_size)\n            else:\n                decoder_output, *decoder_states = decoder_model.predict([decoder_k_inputs[:,k]] + states_values[k], batch_size=batch_size)\n\n            # Top K scores\n            top_k = np.argsort(decoder_output[:, -1, :], axis=-1)[:, -K:]\n            for b in range(no_samples):\n                All_k_beams[b] += [(\n                    decoder_k_out[b][k][0] + np.log(decoder_output[b, -1, top_k[b][i]]),\n                    decoder_k_out[b][k][1] + [top_k[b][i]]\n                ) for i in range(K)]\n\n                if attention:\n                    All_attn_scores[b] += [attn_score[b]] * K if attn_k_scores[b][k] is None \\\n                                          else [np.concatenate((attn_k_scores[b][k], attn_score[b]), axis=0)] * K\n            \n                if target_seqs is not None:\n                    All_errors[b] += [errors[b][k] - np.log(decoder_output[b, -1, target_seqs[b, it]])] * K\n                \n                All_decoder_states[b] += [[state[b:b+1] for state in decoder_states]] * K\n        \n        # Sort and choose top K with max probabilities\n        sorted_ind = list(range(len(All_k_beams[0])))\n        sorted_ind = [sorted(sorted_ind, key = lambda ix: All_k_beams[b][ix][0])[-K:][::-1] for b in range(no_samples)]\n        \n        # Choose the top K decoder output sequences till now\n        decoder_k_out = [[All_k_beams[b][ind] for ind in sorted_ind[b]] for b in range(no_samples)]\n\n        # Update the input sequence for next 1 timestep\n        decoder_k_inputs = np.array([[All_k_beams[b][ind][1][-1] for ind in sorted_ind[b]] for b in range(no_samples)])\n\n        # Update states\n        states_values = [All_decoder_states[0][ind] for ind in sorted_ind[0]]\n        for b in range(1, no_samples):\n            states_values = [[np.concatenate((states_values[i][j], All_decoder_states[b][ind][j])) \n                              for j in range(len(All_decoder_states[b][ind]))] for i,ind in enumerate(sorted_ind[b])]\n\n        # Update attention scores\n        if attention:\n            attn_k_scores = [[All_attn_scores[b][ind] for ind in sorted_ind[b]] for b in range(no_samples)]\n\n        # Update errors\n        if target_seqs is not None:\n            errors = [[All_errors[b][ind] for ind in sorted_ind[b]] for b in range(no_samples)]\n\n    final_outputs = np.array([[decoder_k_out[b][i][1] for i in range(K)] for b in range(no_samples)])\n    if target_seqs is not None:\n        final_errors = np.array(errors) / max_decoder_timesteps\n    if attention:\n        final_attn_scores = np.array(attn_k_scores)\n\n    return final_outputs, final_errors, np.array(states_values), final_attn_scores\n\n\ndef calc_metrics(k_outputs, target_seqs, char_enc, char_dec, k_errors=None, exact_word=True):\n    \n    '''\n    Calculates the accuracy (and mean error if info provided) for the best of K possible output sequences\n    target_seqs -- Expected output (encoded sequence)\n    k_outputs -- k choices of output sequences for each sample\n    '''\n\n    matches = np.mean(k_outputs == np.repeat(target_seqs.reshape((target_seqs.shape[0], 1, target_seqs.shape[1])), k_outputs.shape[1], axis=1), axis=-1)\n    best_k = np.argmax(matches, axis=-1)\n    best_ind = (tuple(range(best_k.shape[0])), tuple(best_k))\n    accuracy = np.mean(matches[best_ind])\n\n    loss = None\n    if k_errors is not None:\n        loss = np.mean(k_errors[best_ind])\n    if exact_word:\n        equal = [0] * k_outputs.shape[0]\n        true_out = convert_to_word(target_seqs, char_enc, char_dec)\n        for k in range(k_outputs.shape[1]):\n            pred_out = convert_to_word(k_outputs[:,k], char_enc, char_dec)\n            equal = [equal[i] or (pred_out[i] == true_out[i]) for i in range(k_outputs.shape[0])]\n        exact_accuracy = np.mean(equal)\n\n        return accuracy, exact_accuracy, loss\n    \n    return accuracy, loss\n\n\ndef beam_decoder(model, input_seqs, target_seqs_onehot, max_decoder_timesteps, char_enc, char_dec, K=1, \n                 model_batch_size=64, attention=True, infer_batch_size=512, exact_word=True, return_outputs=False, \n                 return_states=False, return_attn_scores=False):\n    '''\n    Function to calculate/capture character-wise accuracy, exact-word-match accuracy, and loss for the seq2seq model using a beam decoder.\n    Inputs:\n        model -- model used for training\n        input_seqs -- input to encoder(numpy array, shape : (None, timesteps))\n        target_seqs -- expected target in onehot format(numpy array, shape : (None, timesteps, decoder_vocab_size))\n        max_decoder_timesteps -- Number of timesteps to infer in decoder(int)\n        char_enc -- target character encoding(dict)\n        char_dec -- target character decoding(list)\n        K -- beam width to be used in beam decoder(int, default : 1)\n        model_batch_size -- batch size to be used while evaluating model using Keras(int, default : 64)\n        attention -- whether the model has attention or not(bool, defualt : False)\n        infer_batch_size -- number of samples to be sent to beam_decoder_infer() at a time(int, default : 512)\n        exact_word -- whether or not exact_accuracy has(bool, default : True)\n        return_outputs -- whether or not the outputs predicted need to be returned(bool, default : True)\n        return_states -- whether or not the decoder hidden states need to be returned(bool, default : True)\n        return_attn_scores -- whether or not the attention scores need to be returned(bool, default : True)\n    Outputs:\n        accuracy -- the character-wise match accuracy(float)\n        (If exact_word is True) exact_accuracy -- (float) the exact word match accuracy\n        loss -- (float) the cross-entropy loss for the top K predictions\n        (If return_outputs is True) k_outputs -- (numpy ndarray of size : (None, K, timesteps)) top K output sequences\n        (If return_states is True) k_states -- (numpy ndarray of size : (K, None, timesteps, h_layer_size))  hidden states of decoder\n        (If return_attn_scores is True) k_attn_scores -- (numpy ndarray of size : (None, K, decoder_timesteps, encoder_timesteps)) attention scores\n    '''\n    \n    target_seqs = np.argmax(target_seqs_onehot, axis=-1)\n    k_outputs, k_errors, k_states, k_attn_scores = None, None, None, None\n    for i in range(0, input_seqs.shape[0], infer_batch_size):\n        tmp_k_outputs, tmp_k_errors, tmp_k_states, tmp_k_attn_scores = beam_decoder_infer(model, input_seqs[i:i+infer_batch_size], \n                                                                                          max_decoder_timesteps, K, \n                                                                                          target_seqs[i:i+infer_batch_size], char_enc['\\t'], \n                                                                                          model_batch_size, attention)\n        if k_errors is None:\n            k_outputs, k_errors, k_states, k_attn_scores = tmp_k_outputs, tmp_k_errors, tmp_k_states, tmp_k_attn_scores\n        else:\n            k_outputs = np.concatenate((k_outputs, tmp_k_outputs))\n            k_errors = np.concatenate((k_errors, tmp_k_errors))\n            k_states = np.concatenate((k_states, tmp_k_states), axis=2)\n            k_attn_scores = np.concatenate((k_attn_scores, tmp_k_attn_scores))\n\n    return_elements = []\n    if return_outputs:\n        return_elements += [k_outputs]\n    if return_states:\n        return_elements += [k_states]\n    if return_attn_scores:\n        return_elements += [k_attn_scores]\n\n    if len(return_elements) > 0:\n        return calc_metrics(k_outputs, target_seqs, char_enc, char_dec, k_errors, exact_word) + tuple(return_elements)\n\n    return calc_metrics(k_outputs, target_seqs, char_enc, char_dec, k_errors, exact_word)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.339502Z","iopub.execute_input":"2022-05-02T18:22:16.339910Z","iopub.status.idle":"2022-05-02T18:22:16.380170Z","shell.execute_reply.started":"2022-05-02T18:22:16.339874Z","shell.execute_reply":"2022-05-02T18:22:16.379490Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Custom class to calculate word level and charecter level validation accuracy","metadata":{}},{"cell_type":"code","source":"class customValidation(keras.callbacks.Callback):\n    # Custom class to provide callback after each epoch of training to calculate custom metrics for validation set with beam decoder\n    def __init__(self, val_enc_input, val_dec_target, beam_width=1, batch_size=64, attention=False):\n        self.beam_width = beam_width\n        self.validation_input = val_enc_input\n        self.validation_target = val_dec_target\n        self.batch_size = batch_size\n        self.attention = attention\n\n    def on_epoch_end(self, epoch, logs):\n        val_accuracy, val_exact_accuracy, val_loss = beam_decoder(self.model, self.validation_input, self.validation_target, max_decoder_seq_length, \n                                                                  target_char_enc, target_char_dec, self.beam_width, self.batch_size, self.attention)\n\n        # Log them to reflect in WANDB callback and EarlyStopping\n        logs[\"val_accuracy\"] = val_accuracy\n        logs[\"val_exact_accuracy\"] = val_exact_accuracy\n        logs[\"val_loss\"] = val_loss             # Validation loss calculates categorical cross entropy loss\n\n        print(\"— val_loss: {:.4f} — val_accuracy: {:.4f} — val_exact_accuracy: {:.4f}\".format(val_loss, val_accuracy, val_exact_accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.381451Z","iopub.execute_input":"2022-05-02T18:22:16.381724Z","iopub.status.idle":"2022-05-02T18:22:16.392364Z","shell.execute_reply.started":"2022-05-02T18:22:16.381692Z","shell.execute_reply":"2022-05-02T18:22:16.391726Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Train Function","metadata":{}},{"cell_type":"code","source":"def train(model, train_input_data, train_target_data, val_input_data, val_target_data, beam_width = 5, attention = True,\n                batch_size = 256, optimizer = 'adam', learning_rate = 0.001, epochs = 10, loss_fn = 'categorical_crossentropy'):\n    \n    # Function to train the model using the mentioned optimizer, learning rate and epochs using given training and validation data\n\n    if optimizer == 'adam':\n        model.compile(optimizer = Adam(learning_rate=learning_rate), loss = loss_fn, metrics = ['accuracy'])\n    elif optimizer == 'momentum':\n        model.compile(optimizer = SGD(learning_rate=learning_rate, momentum = 0.9), loss = loss_fn, metrics = ['accuracy'])\n    elif optimizer == 'rmsprop':\n        model.compile(optimizer = RMSprop(learning_rate=learning_rate), loss = loss_fn, metrics = ['accuracy'])\n    elif optimizer == 'nesterov':\n        model.compile(optimizer = SGD(learning_rate=learning_rate, momentum = 0.9, nesterov = True), loss = loss_fn, metrics = ['accuracy'])\n    elif optimizer == 'nadam':\n        model.compile(optimizer = Nadam(learning_rate=learning_rate), loss = loss_fn, metrics = ['accuracy'])\n    else:\n        model.compile(optimizer = SGD(learning_rate=learning_rate), loss = loss_fn, metrics = ['accuracy'])\n\n    # Using validation accuracy as the metric\n    model.fit(train_input_data,\n              train_target_data,\n              batch_size = batch_size,\n              epochs = epochs,\n              callbacks = [customValidation(val_input_data[0], val_target_data, beam_width, batch_size, attention)]\n                            #WandbCallback(monitor='val_accuracy'), EarlyStopping(monitor='val_accuracy', patience=5)]\n             )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.393522Z","iopub.execute_input":"2022-05-02T18:22:16.393835Z","iopub.status.idle":"2022-05-02T18:22:16.406034Z","shell.execute_reply.started":"2022-05-02T18:22:16.393801Z","shell.execute_reply":"2022-05-02T18:22:16.405146Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Function to check the similarity between two strings","metadata":{}},{"cell_type":"code","source":"def levenshtein_dist(s1, s2):\n    # Function to calculate levenshtein distance between two sequences usign Dynamic Programming\n    m, n = len(s1)+1, len(s2)+1\n    # Initialisation\n    dp = np.zeros((m, n))\n    # Base case\n    dp[0,1:] = np.arange(1,n)\n    dp[1:,0] = np.arange(1,m)\n\n    # Recursion\n    for i in range(1,m):\n        for j in range(1,n):\n            if s1[i-1] == s2[j-1]:\n                dp[i,j] = min(dp[i-1,j-1], dp[i-1,j]+1, dp[i,j-1]+1)\n            else:\n                dp[i,j] = min(dp[i,j-1], dp[i-1,j], dp[i-1,j-1]) + 1\n    \n    return dp[m-1,n-1]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.407276Z","iopub.execute_input":"2022-05-02T18:22:16.407703Z","iopub.status.idle":"2022-05-02T18:22:16.418629Z","shell.execute_reply.started":"2022-05-02T18:22:16.407655Z","shell.execute_reply":"2022-05-02T18:22:16.417951Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Test Model","metadata":{}},{"cell_type":"code","source":"def test(model, test_enc_input, test_dec_target, max_decoder_seq_length, target_char_enc, target_char_dec, attention=True, save_pred=False, test_input=None):\n    '''\n    Function to evaluate the model metrics on test data and optionally save the predictions.\n    Inputs :\n        run_id -- WANDB run ID for the trained model(string)\n        test_enc_input -- input to encoder(numpy array shape : (None, timesteps)) (where characters are encoded as integers)\n        test_dec_target -- expected target in onehot format(numpy array shape : (None, timesteps, decoder_vocab_size))\n        max_decoder_seq_length -- number of timesteps in the decoder(int)\n        target_enc_enc -- target character encoding(dict)\n        target_char_dec -- target character decoding(list)\n        attention -- whether or not the model uses attention(bool, default : False)\n        save_pred -- whether or not to save the predictions in a csv file(bool, default : False)\n        test_input -- (list of string : (no_samples, input word), default : None) input as words (needed while saving predictions to file alone)\n    Outputs :\n        acc -- character-wise match accuracy(float)\n        exact_K_acc -- exact word match accuracy using the beam width for the model(float)\n        exact_acc -- exact word match accuracy using the first prediction (float)(which is equivalent to beam width = 1)\n        loss -- loss value(float)\n        true_out -- true output(list of string : (no_samples, word))\n        pred_out -- predicted output(2D list of string : (no_samples, K, word))\n        pred_scores -- levenshtein distance of prediction to true output(2D list : (no_samples, K))\n        attn_scores -- attention scores(numpy ndarray of size : (None, K, decoder_timesteps, encoder_timesteps))\n        model -- the model obtained from the run\n    '''\n    \n    #api = wandb.Api()\n    #prev_run = api.run('abisheks/assignment3/'+run_id)\n    #prev_model_file = prev_run.file('model-best.h5').download(replace=True)\n    #if attention:\n     #   model = keras.models.load_model(prev_model_file.name, custom_objects={'AttentionLayer': AttentionLayer})\n    #else:\n     #   model = keras.models.load_model(prev_model_file.name)\n    #config_file = prev_run.file('config.yaml').download(replace=True)\n    #with open(config_file.name, 'r') as file:\n     #   config = yaml.safe_load(file)\n    \n\n    no_samples, K, batch_size = test_enc_input.shape[0], 5, 64\n    acc, exact_K_acc, loss, outputs, attn_scores = beam_decoder(model, test_enc_input, test_dec_target, max_decoder_seq_length, target_char_enc, \n                                                                target_char_dec, K, batch_size, attention,\n                                                                return_outputs=True, return_attn_scores=True)\n    \n    print(f'Test accuracy (using exact word match with beam width = {K}) : {exact_K_acc*100:.2f}%')\n\n    test_target = np.argmax(test_dec_target, axis=-1)\n    true_out = convert_to_word(test_target, target_char_enc, target_char_dec)\n    pred_out = [[] for _ in range(no_samples)]\n    pred_scores = [[] for _ in range(no_samples)]\n    for k in range(K):\n        pred = convert_to_word(outputs[:,k], target_char_enc, target_char_dec)\n        pred_out = [pred_out[b] + [pred[b]] for b in range(no_samples)]\n        pred_scores = [pred_scores[b] + [levenshtein_dist(pred[b], true_out[b])] for b in range(no_samples)]\n    \n    equal = [pred_out[i][0] == true_out[i] for i in range(no_samples)]\n    exact_acc = np.mean(equal)\n\n    print(f'Test accuracy (using exact word match of the first prediction) : {exact_acc*100:.2f}%')\n    print('\\n')\n    \n    if save_pred:\n        # We write the input and top K outputs in decreasing order of probabilities to the file\n        pred_file_name = 'predictions_attention.csv' if not attention else 'predictions_attention.csv'\n        with open(pred_file_name, 'w', newline='') as file:\n            writer = csv.writer(file)\n            writer.writerow([\"Input\"] + [\"Prediction_\"+str(k+1) for k in range(K)])\n            for b in range(no_samples):\n                writer.writerow([test_input[b]] + [pred_out[b][k] for k in range(K)])\n\n    if attention:\n        return acc, exact_K_acc, exact_acc, loss, true_out, pred_out, pred_scores, attn_scores, model\n    return acc, exact_K_acc, exact_acc, loss, true_out, pred_out, pred_scores, model","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.421614Z","iopub.execute_input":"2022-05-02T18:22:16.421841Z","iopub.status.idle":"2022-05-02T18:22:16.439339Z","shell.execute_reply.started":"2022-05-02T18:22:16.421817Z","shell.execute_reply":"2022-05-02T18:22:16.438581Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Function to print sample prediction","metadata":{}},{"cell_type":"code","source":"def get_clr(value, cmap=None):\n    \n  # Function to get appropriate color for a value between 0 and 1 from the default blue to red hard-coded colors or a matplotlib cmap \n  \n  colors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n    '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n    '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n    '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n  if cmap is not None:\n      rgba = matplotlib.cm.get_cmap(cmap)(value)\n      return 'rgb'+str(tuple([int(c*255) for c in rgba[:-1]]))\n  value = min(int((value * 100) / 5), 19)\n  return colors[value]\n\ndef visualize_samples(input, true_out, pred_out, pred_scores, rand_seq=None):\n    \n    '''\n    Function to print sample outputs in a neat format\n    Arguments :\n        input -- input words\n        true_out -- true output as words\n        pred_out -- K predicted output words\n        pred_scores -- levenshtein distance for the predictions to the true output\n        rand_seq -- list of indices from the dataset passed for which the sample outputs are to be printed (If None, random 10 samples will be chosen)\n    Returns :\n        rand_seq -- the list of indices for which sample outputs are printed\n    '''\n    \n    n_samples = len(true_out)\n    if rand_seq is None:\n        rand_seq = np.random.randint(n_samples, size=(10,))\n    print('-'*20 + f' Top {len(pred_scores[0])} predictions in decreasing order of probabilities for 10 random samples ' + '-'*20)\n    print('')\n    for i in rand_seq:\n        K = len(pred_scores[i])\n        html_str = '''\n        <table style=\"border:2px solid black; border-collapse:collapse\">\n        <caption> <strong>INPUT :</strong> {} &emsp; | &emsp; <strong> TRUE OUTPUT : </strong> {} </caption>\n        <tr>\n        <th scope=\"row\" style=\"border:1px solid black;padding:10px;text-align:left\"> Top {} Predictions </th>\n        '''.format(input[i], true_out[i], K)\n        for k in range(K):\n            html_str += '''\n            <td style=\"color:#000;background-color:{};border:1px solid black;padding:10px\"> {} </td>\n            '''.format(get_clr(pred_scores[i][k]/5), pred_out[i][k])\n        html_str += '''\n        </tr>\n        <tr>\n        <th scope=\"row\" style=\"border:1px solid black;padding:10px;text-align:left\"> Levenshtein distance (to true output) &emsp; </th>\n        '''\n        for k in range(K):\n            html_str += '''\n            <td style=\"border:1px solid black;padding:10px\"> {} </td>\n            '''.format(pred_scores[i][k])\n        html_str += '''\n        </tr>\n        </table>\n        '''\n        display(html_print(html_str))\n        print('\\n\\n')\n    \n    return rand_seq","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.440634Z","iopub.execute_input":"2022-05-02T18:22:16.440923Z","iopub.status.idle":"2022-05-02T18:22:16.454351Z","shell.execute_reply.started":"2022-05-02T18:22:16.440881Z","shell.execute_reply":"2022-05-02T18:22:16.453647Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"'''model = build_model(len(input_char_dec), len(target_char_dec), inp_emb_size=256, n_enc_layers=2, \n                         n_dec_layers=3, h_layer_size=256, cell_type='LSTM', dropout=0.3, r_dropout=0)'''","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.457450Z","iopub.execute_input":"2022-05-02T18:22:16.457630Z","iopub.status.idle":"2022-05-02T18:22:16.468299Z","shell.execute_reply.started":"2022-05-02T18:22:16.457608Z","shell.execute_reply":"2022-05-02T18:22:16.467559Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"'''model = train(model, [train_enc_x,train_dec_x], train_dec_y, [val_enc_x,val_dec_x], val_dec_y)\nmodel.save(\"best_model_attn.h5\")'''","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.469508Z","iopub.execute_input":"2022-05-02T18:22:16.469850Z","iopub.status.idle":"2022-05-02T18:22:16.477392Z","shell.execute_reply.started":"2022-05-02T18:22:16.469814Z","shell.execute_reply":"2022-05-02T18:22:16.476408Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"'''test_acc, test_exact_K_acc, test_exact_acc, test_loss, test_true_out, test_pred_out, test_pred_scores,attn_scores, model = test(model, test_enc_x, test_dec_y, max_decoder_seq_length, target_char_enc, target_char_dec, True)'''","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.479212Z","iopub.execute_input":"2022-05-02T18:22:16.479549Z","iopub.status.idle":"2022-05-02T18:22:16.486125Z","shell.execute_reply.started":"2022-05-02T18:22:16.479514Z","shell.execute_reply":"2022-05-02T18:22:16.485099Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"!wandb login 48af1d62ac54f77717fbb3680bc61c553ce36124\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:16.487850Z","iopub.execute_input":"2022-05-02T18:22:16.488430Z","iopub.status.idle":"2022-05-02T18:22:20.658248Z","shell.execute_reply.started":"2022-05-02T18:22:16.488391Z","shell.execute_reply":"2022-05-02T18:22:20.657519Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Sweep wrapper function for running sweeps","metadata":{}},{"cell_type":"code","source":"def wandb_wrapper():\n    # Wrapper function to call the seq2seq_no_attention() function for sweeping with different hyperparameters\n    \n    wandb.init(project=\"Seq2SeqLearning\", entity=\"cs21s048-cs21s058\")\n\n    # Config is a variable that holds and saves hyperparameters and inputs\n    config = wandb.config\n\n    wandb.run.name = f'ie_{config.inp_emb_size}_ne_{config.n_enc_layers}_de_{config.n_dec_layers}_ct_{config.cell_type}_dr_{config.dropout}'\n    wandb.run.name += f'_da_{config.h_layer_size}_K_{config.beam_width}'\n    wandb.run.save()\n    print(wandb.run.name)\n    \n    model = build_model(len(input_char_dec), len(target_char_dec), config.inp_emb_size, config.n_enc_layers, \n                         config.n_dec_layers, config.h_layer_size, config.cell_type, config.dropout, config.dropout)\n    \n    model = train(model = model, train_input_data= [train_enc_x,train_dec_x], train_target_data= train_dec_y, \n                      val_input_data= [val_enc_x,val_dec_x], val_target_data= val_dec_y, beam_width= config.beam_width,\n                      attention = True, batch_size= config.batch_size, optimizer = 'adam', learning_rate= config.learning_rate, \n                      epochs= config.epochs)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:20.659813Z","iopub.execute_input":"2022-05-02T18:22:20.660341Z","iopub.status.idle":"2022-05-02T18:22:20.669224Z","shell.execute_reply.started":"2022-05-02T18:22:20.660298Z","shell.execute_reply":"2022-05-02T18:22:20.668185Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### Setting up wandb sweeps","metadata":{}},{"cell_type":"code","source":"sweep_config = {\n    'name': 'Seq2SeQ_with_Attention',\n    'method': 'bayes',            \n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'epochs': {\n            'values': [10, 15]\n        },\n        'batch_size': {\n            'values': [128, 256]\n        },\n        'inp_emb_size': {\n            'values': [256, 512]\n        },\n        'n_enc_layers': {\n            'values': [1, 2]\n        },\n        'n_dec_layers': {\n            'values': [3, 5]\n        },\n        'h_layer_size': {\n            'values': [256, 512, 768]\n        },\n        'cell_type': {\n            'values': ['RNN', 'LSTM', 'GRU']\n        },\n        'dropout' :{\n            'values': [0, 0.3]\n        },\n        'beam_width': {\n            'values': [1, 3, 5]\n        },\n        'learning_rate': {\n            'values': [0.001, 0.0001, 0.0005]\n        }\n    }\n}\n\n#creating the sweep\nsweep_id = wandb.sweep(sweep_config, project=\"Seq2SeqLearning\", entity=\"cs21s048-cs21s058\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:20.671269Z","iopub.execute_input":"2022-05-02T18:22:20.671877Z","iopub.status.idle":"2022-05-02T18:22:21.263363Z","shell.execute_reply.started":"2022-05-02T18:22:20.671839Z","shell.execute_reply":"2022-05-02T18:22:21.262468Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"wandb.agent('vu3w7i97', function=wandb_wrapper, count=100)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T18:22:21.264816Z","iopub.execute_input":"2022-05-02T18:22:21.265166Z"},"trusted":true},"execution_count":null,"outputs":[]}]}