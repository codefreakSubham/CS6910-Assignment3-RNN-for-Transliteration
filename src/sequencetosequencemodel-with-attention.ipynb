{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Useful Imports\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport cv2\nimport pathlib\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.utils.vis_utils import plot_model\nimport csv\nfrom IPython.display import HTML as html_print\nfrom IPython.display import display\nfrom matplotlib.font_manager import FontProperties","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-07T16:08:05.222538Z","iopub.execute_input":"2022-05-07T16:08:05.222876Z","iopub.status.idle":"2022-05-07T16:08:10.872654Z","shell.execute_reply.started":"2022-05-07T16:08:05.222783Z","shell.execute_reply":"2022-05-07T16:08:10.871901Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"if os.path.exists('best_model_attn.h5'):\n    os.remove('best_model_attn.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:10.876126Z","iopub.execute_input":"2022-05-07T16:08:10.876329Z","iopub.status.idle":"2022-05-07T16:08:10.884647Z","shell.execute_reply.started":"2022-05-07T16:08:10.876304Z","shell.execute_reply":"2022-05-07T16:08:10.881564Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Downloading the Dakshina dataset","metadata":{}},{"cell_type":"code","source":"#Downloading\n!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n    \n#Uncompressing\n!tar -xf dakshina_dataset_v1.0.tar","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:10.886155Z","iopub.execute_input":"2022-05-07T16:08:10.886736Z","iopub.status.idle":"2022-05-07T16:08:29.204420Z","shell.execute_reply.started":"2022-05-07T16:08:10.886699Z","shell.execute_reply":"2022-05-07T16:08:29.203340Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Pre processing data","metadata":{}},{"cell_type":"code","source":"def read(data_path, characters = False):\n    \n    # Returns the (x, y) pair from the dataset\n    # If characters == True, the input/output sample would be in the form list of characters, else as string\n\n    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n        lines = [line.split(\"\\t\") for line in f.read().split(\"\\n\") if line != '']\n    \n    x, y = [val[1] for val in lines], [val[0] for val in lines]\n    '''if characters:\n        input, target = [list(inp_str) for inp_str in input], [list(tar_str) for tar_str in target]'''\n    return x, y","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:29.209145Z","iopub.execute_input":"2022-05-07T16:08:29.211120Z","iopub.status.idle":"2022-05-07T16:08:29.217163Z","shell.execute_reply.started":"2022-05-07T16:08:29.211086Z","shell.execute_reply":"2022-05-07T16:08:29.216467Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"START_CHAR = '\\t'\nEND_CHAR = '\\n'\nBLANK_CHAR = ' '\ndef encode_decode_characters(train_input, train_target, val_input, val_target):\n    \n    # Returns the encoding for characters to integer (as a dictionary) and decoding for integers to characters (as a list) for input and target data\n    # Encoding and decoding of input vocabulary\n    \n    input_char_enc = {}\n    input_char_dec = []\n    max_encoder_seq_length = 1\n    for string in train_input + val_input:\n        max_encoder_seq_length = max(max_encoder_seq_length, len(string))\n        for char in string:\n            if char not in input_char_enc:\n                input_char_enc[char] = len(input_char_dec)\n                input_char_dec.append(char)\n    if BLANK_CHAR not in input_char_enc:\n        input_char_enc[BLANK_CHAR] = len(input_char_dec)\n        input_char_dec.append(BLANK_CHAR)\n        \n    # Encoding and decoding of target vocabulary\n    target_char_enc = {}\n    target_char_dec = []\n    target_char_enc[START_CHAR] = len(target_char_dec)\n    target_char_dec.append(START_CHAR)\n    max_decoder_seq_length = 1\n    for string in train_target + val_target:\n        max_decoder_seq_length = max(max_decoder_seq_length, len(string)+2)\n        for char in string:\n            if char not in target_char_enc:\n                target_char_enc[char] = len(target_char_dec)\n                target_char_dec.append(char)\n    target_char_enc[END_CHAR] = len(target_char_dec)\n    target_char_dec.append(END_CHAR)\n    if ' ' not in target_char_enc:\n        target_char_enc[BLANK_CHAR] = len(target_char_dec)\n        target_char_dec.append(BLANK_CHAR)\n\n    print(\"Number of training samples:\", len(train_input))\n    print(\"Number of validation samples:\", len(val_input))\n    print(\"Number of unique input tokens:\", len(input_char_dec))\n    print(\"Number of unique output tokens:\", len(target_char_dec))\n    print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n    print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n\n    return input_char_enc, input_char_dec, target_char_enc, target_char_dec, max_encoder_seq_length, max_decoder_seq_length","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:29.218634Z","iopub.execute_input":"2022-05-07T16:08:29.219162Z","iopub.status.idle":"2022-05-07T16:08:29.887030Z","shell.execute_reply.started":"2022-05-07T16:08:29.219127Z","shell.execute_reply":"2022-05-07T16:08:29.885258Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def process_data(input, enc_timesteps, input_char_enc, target = None, dec_timesteps = None, target_char_enc = None):\n    \n    # Returns the input and target data in a form needed by the Keras embedding layer (i.e) \n    # decoder_input & encoder_input -- (None, timesteps) where each character is encoded by an integer\n    # decoder_output -- (None, timesteps, vocabulary size) where the last dimension is the one-hot encoding\n    # BLANK_CHAR -- space (equivalent to no meaningful input / blank input)\n    \n    encoder_input = np.array([[input_char_enc[ch] for ch in string] + [input_char_enc[BLANK_CHAR]] * (enc_timesteps - len(string)) for string in input])\n\n    decoder_input, decoder_target = None, None\n    if target is not None and dec_timesteps is not None and target_char_enc is not None:\n        \n        # START_CHAR -- start of sequence, END_CHAR -- end of sequence\n        decoder_input = np.array([[target_char_enc[START_CHAR]] + [target_char_enc[ch] for ch in string] + [target_char_enc[END_CHAR]] \n                                    + [target_char_enc[BLANK_CHAR]] * (dec_timesteps - len(string) - 2) for string in target])\n        decoder_target = np.zeros((decoder_input.shape[0], dec_timesteps, len(target_char_enc)), dtype='float32')\n\n        for i in range(decoder_input.shape[0]):\n            for t, char_ind in enumerate(decoder_input[i]):\n                if t > 0:\n                    decoder_target[i,t-1,char_ind] = 1.0\n            decoder_target[i,t:,target_char_enc[BLANK_CHAR]] = 1.0\n\n    return encoder_input, decoder_input, decoder_target","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:29.890088Z","iopub.execute_input":"2022-05-07T16:08:29.890330Z","iopub.status.idle":"2022-05-07T16:08:30.060506Z","shell.execute_reply.started":"2022-05-07T16:08:29.890297Z","shell.execute_reply":"2022-05-07T16:08:30.059634Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_x, train_y = read('./dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv')\nval_x, val_y = read('./dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv')\ntest_x, test_y = read('./dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv')\n\n# Assigning encoding and decoding for input and target characters\ninput_char_enc, input_char_dec, target_char_enc, target_char_dec, max_encoder_seq_length, max_decoder_seq_length = encode_decode_characters(\n    train_x, train_y, val_x, val_y)\n\n# Assigning training, validation and test encoder input, decoder input, decoder output\ntrain_enc_x, train_dec_x, train_dec_y = process_data(train_x, max_encoder_seq_length, input_char_enc, train_y, \n                                                                  max_decoder_seq_length, target_char_enc)\nval_enc_x, val_dec_x, val_dec_y = process_data(val_x, max_encoder_seq_length, input_char_enc, val_y, \n                                                            max_decoder_seq_length, target_char_enc)\ntest_enc_x, test_dec_x, test_dec_y = process_data(test_x, max_encoder_seq_length, input_char_enc, test_y, \n                                                               max_decoder_seq_length, target_char_enc)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:30.062037Z","iopub.execute_input":"2022-05-07T16:08:30.062331Z","iopub.status.idle":"2022-05-07T16:08:35.622701Z","shell.execute_reply.started":"2022-05-07T16:08:30.062286Z","shell.execute_reply":"2022-05-07T16:08:35.621984Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def convert_to_word(predictions, char_enc, char_dec = None):\n    \n    # Function to return the predictions after cutting the END_CHAR and BLANK_CHAR s at the end.\n    # If char_dec == None, the predictions are in the form of decoded string, otherwise as list of integers\n    \n    no_samples = len(predictions) if type(predictions) is list else predictions.shape[0]\n    pred_words = ['' for _ in range(no_samples)]\n    for i, pred_list in enumerate(predictions):\n        for l in pred_list:\n            # Stop word : END_CHAR\n            if l == char_enc[END_CHAR]:\n                break\n            pred_words[i] += char_dec[l] if char_dec is not None else l\n    \n    return pred_words","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:35.624107Z","iopub.execute_input":"2022-05-07T16:08:35.624565Z","iopub.status.idle":"2022-05-07T16:08:35.631222Z","shell.execute_reply.started":"2022-05-07T16:08:35.624528Z","shell.execute_reply":"2022-05-07T16:08:35.630446Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Seq2Seq Model (with Attention)","metadata":{}},{"cell_type":"markdown","source":"### Creating Attention layer\nSource referenced : https://github.com/thushv89/attention_keras/blob/master/src/layers/attention.py","metadata":{}},{"cell_type":"code","source":"from keras.layers import Layer\nimport keras.backend as K\n\nclass AttentionLayer(Layer):\n    \"\"\"\n    Source referenced : https://github.com/thushv89/attention_keras/blob/master/src/layers/attention.py\n    W_a, U_a, and V_a - 3 sets of weights\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super(AttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert isinstance(input_shape, list)\n        # Create a trainable weight variable for this layer.\n\n        self.W_a = self.add_weight(name='W_a',\n                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.U_a = self.add_weight(name='U_a',\n                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.V_a = self.add_weight(name='V_a',\n                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n                                   initializer='uniform',\n                                   trainable=True)\n\n        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, inputs, verbose=False):\n        \"\"\"\n        inputs: [encoder_output_sequence, decoder_output_sequence]\n        \"\"\"\n        assert type(inputs) == list\n        encoder_out_seq, decoder_out_seq = inputs\n        if verbose:\n            print('encoder_out_seq>', encoder_out_seq.shape)\n            print('decoder_out_seq>', decoder_out_seq.shape)\n\n        def energy_step(inputs, states):\n            \n            \"\"\" Step function for computing energy for a single decoder state\n            inputs: (batchsize * 1 * de_in_dim)\n            states: (batchsize * 1 * de_latent_dim)\n            \"\"\"\n\n            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n\n            \"\"\" Some parameters required for shaping tensors\"\"\"\n            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n            de_hidden = inputs.shape[-1]\n\n            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n            # <= batch size * en_seq_len * latent_dim\n            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n\n            \"\"\" Computing hj.Ua \"\"\"\n            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n            if verbose:\n                print('Ua.h>', U_a_dot_h.shape)\n\n            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n            # <= batch_size*en_seq_len, latent_dim\n            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n            if verbose:\n                print('Ws+Uh>', Ws_plus_Uh.shape)\n\n            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n            # <= batch_size, en_seq_len\n            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n            # <= batch_size, en_seq_len\n            e_i = K.softmax(e_i)\n\n            if verbose:\n                print('ei>', e_i.shape)\n\n            return e_i, [e_i]\n\n        def context_step(inputs, states):\n            \"\"\" Step function for computing ci using ei \"\"\"\n\n            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n\n            # <= batch_size, hidden_size\n            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n            if verbose:\n                print('ci>', c_i.shape)\n            return c_i, [c_i]\n\n        fake_state_c = K.sum(encoder_out_seq, axis=1)\n        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n\n        \"\"\" Computing energy outputs \"\"\"\n        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n        last_out, e_outputs, _ = K.rnn(\n            energy_step, decoder_out_seq, [fake_state_e],\n        )\n\n        \"\"\" Computing context vectors \"\"\"\n        last_out, c_outputs, _ = K.rnn(\n            context_step, e_outputs, [fake_state_c],\n        )\n\n        return c_outputs, e_outputs\n\n    def compute_output_shape(self, input_shape):\n        \"\"\" Outputs produced by the layer \"\"\"\n        return [\n            # (batch_size, decoder_timesteps, decoder_h_layer_size)\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n            # (batch_size, decoder_timesteps, encoder_timesteps)\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n        ]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:35.633201Z","iopub.execute_input":"2022-05-07T16:08:35.633566Z","iopub.status.idle":"2022-05-07T16:08:37.191604Z","shell.execute_reply.started":"2022-05-07T16:08:35.633529Z","shell.execute_reply":"2022-05-07T16:08:37.190771Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Building the model","metadata":{}},{"cell_type":"code","source":"def build_model(encoder_vocab_size, decoder_vocab_size, inp_emb_size=64, n_enc_layers=1, n_dec_layers=1, \n                           h_layer_size=64, cell_type='LSTM', dropout=0, r_dropout=0, cell_activation='tanh'):\n    '''\n    Function to create a seq2seq model without attention.\n    Input :\n        encoder_vocab_size -- number of characters in input vocabulary (int)\n        decoder_vocab_size -- number of characters in output vocabulary (int)\n        inp_emb_size -- size of input embedding layer for encoder and decoder (int, default value : 64)\n        n_enc_layers -- number of layers of cell to stack in encoder (int, default value : 1)\n        n_dec_layers -- number of layers of cell to stack in decoder (int, default value : 1)\n        h_layer_size -- size of hidden layer of the encoder and decoder cells (int, default : 64)\n        cell_type -- type of cell used in encoder and decoder (string('LSTM'/ 'GRU'/ 'RNN'), default : 'LSTM')\n        dropout -- value of normal dropout (float(between 0 and 1), default : 0.0)\n        r_dropout -- value of recurrent dropout (float(between 0 and 1), default : 0.0)\n        cell_activation -- type of activation used in the cell (string, default : 'tanh')\n    Output :\n        model -- (Keras model object)\n    '''\n    \n    # Getting cell type\n    get_cell = {\n        'RNN': keras.layers.SimpleRNN,\n        'GRU': keras.layers.GRU,\n        'LSTM': keras.layers.LSTM\n    }\n    # Encoder input and embedding\n    encoder_input = keras.layers.Input(shape=(None,), name=\"input_1\")\n    encoder_inp_emb = keras.layers.Embedding(encoder_vocab_size, inp_emb_size, name=\"embedding_1\")(encoder_input)\n\n    # Encoder cell layers\n    encoder_seq, *encoder_state = get_cell[cell_type](h_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n                                                      dropout=dropout, recurrent_dropout=r_dropout, name=\"encoder_1\")(\n                                                            encoder_inp_emb\n                                                     )\n    for i in range(1, n_enc_layers):\n        encoder_seq, *encoder_state = get_cell[cell_type](h_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n                                                          dropout=dropout, recurrent_dropout=r_dropout, name=\"encoder_\"+str(i+1))(\n                                                                encoder_seq\n                                                         )\n    # Decoder input and embedding\n    decoder_input = keras.layers.Input(shape=(None,), name=\"input_2\")\n    decoder_inp_emb = keras.layers.Embedding(decoder_vocab_size, inp_emb_size, name=\"embedding_2\")(decoder_input)\n    decoder_seq = decoder_inp_emb\n    # Decoder cell layers\n    for i in range(n_dec_layers-1):\n        decoder_seq, *_ = get_cell[cell_type](h_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n                                              dropout=dropout, recurrent_dropout=r_dropout, name=\"decoder_\"+str(i+1))(\n                                                    decoder_seq, initial_state=encoder_state\n                                             )\n    # Decoder last layer\n    decoder_seq, *_ = get_cell[cell_type](h_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n                                          dropout=dropout, recurrent_dropout=r_dropout, name=\"decoder_1\")(\n                                                decoder_inp_emb, initial_state=encoder_state\n                                         )\n\n    # Attention layer\n    attn_out, attn_scores = AttentionLayer(name='attention_1')([encoder_seq, decoder_seq])        # Bahdanau Attention\n    # Concat attention output and decoder output\n    dense_concat_input = keras.layers.Concatenate(axis=-1, name='concat_layer_1')([decoder_seq, attn_out])\n\n    # Time distributed Softmax FC layer\n    decoder_dense_layer = keras.layers.Dense(decoder_vocab_size, activation=\"softmax\", name=\"dense_1\")\n    decoder_dense_output = decoder_dense_layer(dense_concat_input)\n\n    # Define the model that will turn encoder_input_data and decoder_input_data into decoder_target_data\n    model = keras.Model([encoder_input, decoder_input], decoder_dense_output)\n\n    model.summary(line_length=150)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:37.195326Z","iopub.execute_input":"2022-05-07T16:08:37.195584Z","iopub.status.idle":"2022-05-07T16:08:37.682208Z","shell.execute_reply.started":"2022-05-07T16:08:37.195542Z","shell.execute_reply":"2022-05-07T16:08:37.681170Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Inference Model (with attention)","metadata":{}},{"cell_type":"code","source":"def create_attention_inference_model(model):\n    \n    '''\n    Function to return models needed for inference from the original model (without attention).\n    Inputs :\n        model -- non-attention model used for training\n    Outputs :\n        encoder_model \n        deocder_model\n        n_enc_layers -- number of layers in the encoder(int)\n        n_dec_layers -- number of layers in the decoder(int)\n    '''\n    \n    # Calculating number of layers in encoder and decoder\n    n_enc_layers, n_dec_layers = 0, 0\n    for layer in model.layers:\n        n_enc_layers += layer.name.startswith('encoder')\n        n_dec_layers += layer.name.startswith('decoder')\n\n    # Encoder input\n    encoder_input = model.input[0]      # Input_1\n    # Encoder cell final layer\n    encoder_cell = model.get_layer(\"encoder_\"+str(n_enc_layers))\n    encoder_type = encoder_cell.__class__.__name__\n    encoder_seq, *encoder_state = encoder_cell.output\n    # Encoder model\n    encoder_model = keras.Model(encoder_input, encoder_state)\n\n    # Decoder input\n    decoder_input = model.input[1]      # Input_2\n    decoder_inp_emb = model.get_layer(\"embedding_2\")(decoder_input)\n    decoder_seq = decoder_inp_emb\n    # Inputs to decoder layers' initial states\n    decoder_states, decoder_state_inputs = [], []\n    for i in range(1, n_dec_layers+1):\n        if encoder_type == 'LSTM':\n            decoder_state_input = [keras.Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(2*i+1)), \n                                   keras.Input(shape=(encoder_state[1].shape[1],), name=\"input_\"+str(2*i+2))]\n        else:\n            decoder_state_input = [keras.Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(i+2))]\n\n        decoder_cell = model.get_layer(\"decoder_\"+str(i))\n        decoder_seq, *decoder_state = decoder_cell(decoder_seq, initial_state=decoder_state_input)\n        decoder_states += decoder_state\n        decoder_state_inputs += decoder_state_input\n\n    # Attention layer\n    attn_out, attn_scores = model.get_layer('attention_1')([encoder_seq, decoder_seq])        # Bahdanau Attention\n    # Concat attention input and decoder output\n    dense_concat_input = keras.layers.Concatenate(axis=-1, name='concat_layer_1')([decoder_seq, attn_out])\n\n    # Softmax FC layer\n    decoder_dense = model.get_layer(\"dense_1\")\n    decoder_dense_output = decoder_dense(dense_concat_input)\n\n    # Decoder model\n    decoder_model = keras.Model(\n        [encoder_input, decoder_input] + decoder_state_inputs, [attn_scores, decoder_dense_output] + decoder_states\n    )\n\n    return encoder_model, decoder_model, n_enc_layers, n_dec_layers","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:37.689007Z","iopub.execute_input":"2022-05-07T16:08:37.691339Z","iopub.status.idle":"2022-05-07T16:08:37.711697Z","shell.execute_reply.started":"2022-05-07T16:08:37.691283Z","shell.execute_reply":"2022-05-07T16:08:37.710750Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Beam Decoder","metadata":{}},{"cell_type":"code","source":"def beam_decoder_infer(model, input_seqs, max_decoder_timesteps, K=1, target_seqs=None, starting_char_enc=0, batch_size=64, attention=True):\n    \n    \n    '''\n    Function to do inference on the model using beam decoder.\n    Inputs :\n        model -- training model\n        input_seqs -- input to encoder(numpy array, shape : (None, timesteps))\n        max_decoder_timesteps -- Number of timesteps to infer in decoder(int)\n        K -- beam width of beam decoder(int, default : 1)\n        target_seqs -- expected target(numpy array, shape : (None, timesteps, decoder_vocab_size), deault : None)\n                       If None, cross entropy errors won't be calculated.\n        starting_char_enc -- Encoding integer for START_CHAR(int, default : 0)\n        batch_size -- batch_size sent to Keras predict(int, default : 64)\n        attention -- whether the model has attention or not(bool, defualt : False)\n        \n    Outputs :\n        final_outputs -- top K output sequences(numpy array, shape : (None, K, timesteps))\n        final_errors -- cross entropy errors for top K output(numpy array, shape : (None, K))\n        states_values -- hidden states of decoder(numpy array, shape : (K, None, timesteps, h_layer_size))\n        final_attn_scores -- attention to all encoder timesteps for a decoder timestep(numpy array, shape : (None, K, decoder_timesteps, encoder_timesteps))\n    '''\n    \n    # Generating output from encoder\n    encoder_model, decoder_model, n_enc_layers, n_dec_layers = create_attention_inference_model(model)\n    encoder_output = encoder_model.predict(input_seqs, batch_size=batch_size)\n    encoder_out = encoder_output if type(encoder_output) is list else [encoder_output]\n\n    # Number of input samples in the data passed\n    no_samples = input_seqs.shape[0]\n\n    # Top K output sequences for each input \n    final_outputs = np.zeros((no_samples, K, max_decoder_timesteps), dtype=np.int32)\n    \n    # Errors for top K output sequences for each input\n    final_errors = np.zeros((no_samples, K))\n    \n    # Attention scores for top K output sequences for each input\n    final_attn_scores = np.zeros((no_samples, K, max_decoder_timesteps, input_seqs.shape[1]))\n\n    # decoder input sequence for 1 timestep (for all samples). Initially one choice only there\n    decoder_k_inputs = np.zeros((no_samples, 1, 1))\n    \n    # Populate the input sequence with the start character at the 1st timestep\n    decoder_k_inputs[:, :, 0] = starting_char_enc\n\n    # (log(probability) sequence, decoder output sequence) pairs for all choices and all samples. Probability starts with log(1) = 0\n    decoder_k_out = [[(0, [])] for _ in range(no_samples)]\n    \n    # Categorical cross entropy error in the sequence for all choice and all samples\n    errors = [[0] for _ in range(no_samples)]\n    \n    # Output states from decoder for all choices, and all samples\n    states_values  = [encoder_out * n_dec_layers]\n\n    # Attention weights output\n    attn_k_scores = [[None] for _ in range(no_samples)]\n\n    # Sampling loop\n    for it in range(max_decoder_timesteps):\n        # Storing respective data for all possibilities\n        All_k_beams = [[] for _ in range(no_samples)]\n        All_decoder_states = [[] for _ in range(no_samples)]\n        All_errors = [[] for _ in range(no_samples)]\n        All_attn_scores = [[] for _ in range(no_samples)]\n\n        for k in range(len(decoder_k_out[0])):\n            if attention:\n                attn_score, decoder_output, *decoder_states = decoder_model.predict([input_seqs, decoder_k_inputs[:,k]] + states_values[k], batch_size=batch_size)\n            else:\n                decoder_output, *decoder_states = decoder_model.predict([decoder_k_inputs[:,k]] + states_values[k], batch_size=batch_size)\n\n            # Top K scores\n            top_k = np.argsort(decoder_output[:, -1, :], axis=-1)[:, -K:]\n            for b in range(no_samples):\n                All_k_beams[b] += [(\n                    decoder_k_out[b][k][0] + np.log(decoder_output[b, -1, top_k[b][i]]),\n                    decoder_k_out[b][k][1] + [top_k[b][i]]\n                ) for i in range(K)]\n\n                if attention:\n                    All_attn_scores[b] += [attn_score[b]] * K if attn_k_scores[b][k] is None \\\n                                          else [np.concatenate((attn_k_scores[b][k], attn_score[b]), axis=0)] * K\n            \n                if target_seqs is not None:\n                    All_errors[b] += [errors[b][k] - np.log(decoder_output[b, -1, target_seqs[b, it]])] * K\n                \n                All_decoder_states[b] += [[state[b:b+1] for state in decoder_states]] * K\n        \n        # Sort and choose top K with max probabilities\n        sorted_ind = list(range(len(All_k_beams[0])))\n        sorted_ind = [sorted(sorted_ind, key = lambda ix: All_k_beams[b][ix][0])[-K:][::-1] for b in range(no_samples)]\n        \n        # Choose the top K decoder output sequences till now\n        decoder_k_out = [[All_k_beams[b][ind] for ind in sorted_ind[b]] for b in range(no_samples)]\n\n        # Update the input sequence for next 1 timestep\n        decoder_k_inputs = np.array([[All_k_beams[b][ind][1][-1] for ind in sorted_ind[b]] for b in range(no_samples)])\n\n        # Update states\n        states_values = [All_decoder_states[0][ind] for ind in sorted_ind[0]]\n        for b in range(1, no_samples):\n            states_values = [[np.concatenate((states_values[i][j], All_decoder_states[b][ind][j])) \n                              for j in range(len(All_decoder_states[b][ind]))] for i,ind in enumerate(sorted_ind[b])]\n\n        # Update attention scores\n        if attention:\n            attn_k_scores = [[All_attn_scores[b][ind] for ind in sorted_ind[b]] for b in range(no_samples)]\n\n        # Update errors\n        if target_seqs is not None:\n            errors = [[All_errors[b][ind] for ind in sorted_ind[b]] for b in range(no_samples)]\n\n    final_outputs = np.array([[decoder_k_out[b][i][1] for i in range(K)] for b in range(no_samples)])\n    if target_seqs is not None:\n        final_errors = np.array(errors) / max_decoder_timesteps\n    if attention:\n        final_attn_scores = np.array(attn_k_scores)\n\n    return final_outputs, final_errors, np.array(states_values), final_attn_scores\n\n\ndef calc_metrics(k_outputs, target_seqs, char_enc, char_dec, k_errors=None, exact_word=True):\n    \n    '''\n    Calculates the accuracy (and mean error if info provided) for the best of K possible output sequences\n    target_seqs -- Expected output (encoded sequence)\n    k_outputs -- k choices of output sequences for each sample\n    '''\n\n    matches = np.mean(k_outputs == np.repeat(target_seqs.reshape((target_seqs.shape[0], 1, target_seqs.shape[1])), k_outputs.shape[1], axis=1), axis=-1)\n    best_k = np.argmax(matches, axis=-1)\n    best_ind = (tuple(range(best_k.shape[0])), tuple(best_k))\n    accuracy = np.mean(matches[best_ind])\n\n    loss = None\n    if k_errors is not None:\n        loss = np.mean(k_errors[best_ind])\n    if exact_word:\n        equal = [0] * k_outputs.shape[0]\n        true_out = convert_to_word(target_seqs, char_enc, char_dec)\n        for k in range(k_outputs.shape[1]):\n            pred_out = convert_to_word(k_outputs[:,k], char_enc, char_dec)\n            equal = [equal[i] or (pred_out[i] == true_out[i]) for i in range(k_outputs.shape[0])]\n        exact_accuracy = np.mean(equal)\n\n        return accuracy, exact_accuracy, loss\n    \n    return accuracy, loss\n\n\ndef beam_decoder(model, input_seqs, target_seqs_onehot, max_decoder_timesteps, char_enc, char_dec, K=1, \n                 model_batch_size=64, attention=True, infer_batch_size=512, exact_word=True, return_outputs=False, \n                 return_states=False, return_attn_scores=False):\n    '''\n    Function to calculate/capture character-wise accuracy, exact-word-match accuracy, and loss for the seq2seq model using a beam decoder.\n    Inputs:\n        model -- model used for training\n        input_seqs -- input to encoder(numpy array, shape : (None, timesteps))\n        target_seqs -- expected target in onehot format(numpy array, shape : (None, timesteps, decoder_vocab_size))\n        max_decoder_timesteps -- Number of timesteps to infer in decoder(int)\n        char_enc -- target character encoding(dict)\n        char_dec -- target character decoding(list)\n        K -- beam width to be used in beam decoder(int, default : 1)\n        model_batch_size -- batch size to be used while evaluating model using Keras(int, default : 64)\n        attention -- whether the model has attention or not(bool, defualt : False)\n        infer_batch_size -- number of samples to be sent to beam_decoder_infer() at a time(int, default : 512)\n        exact_word -- whether or not exact_accuracy has(bool, default : True)\n        return_outputs -- whether or not the outputs predicted need to be returned(bool, default : True)\n        return_states -- whether or not the decoder hidden states need to be returned(bool, default : True)\n        return_attn_scores -- whether or not the attention scores need to be returned(bool, default : True)\n    Outputs:\n        accuracy -- the character-wise match accuracy(float)\n        (If exact_word is True) exact_accuracy -- (float) the exact word match accuracy\n        loss -- (float) the cross-entropy loss for the top K predictions\n        (If return_outputs is True) k_outputs -- (numpy ndarray of size : (None, K, timesteps)) top K output sequences\n        (If return_states is True) k_states -- (numpy ndarray of size : (K, None, timesteps, h_layer_size))  hidden states of decoder\n        (If return_attn_scores is True) k_attn_scores -- (numpy ndarray of size : (None, K, decoder_timesteps, encoder_timesteps)) attention scores\n    '''\n    \n    target_seqs = np.argmax(target_seqs_onehot, axis=-1)\n    k_outputs, k_errors, k_states, k_attn_scores = None, None, None, None\n    for i in range(0, input_seqs.shape[0], infer_batch_size):\n        tmp_k_outputs, tmp_k_errors, tmp_k_states, tmp_k_attn_scores = beam_decoder_infer(model, input_seqs[i:i+infer_batch_size], \n                                                                                          max_decoder_timesteps, K, \n                                                                                          target_seqs[i:i+infer_batch_size], char_enc['\\t'], \n                                                                                          model_batch_size, attention)\n        if k_errors is None:\n            k_outputs, k_errors, k_states, k_attn_scores = tmp_k_outputs, tmp_k_errors, tmp_k_states, tmp_k_attn_scores\n        else:\n            k_outputs = np.concatenate((k_outputs, tmp_k_outputs))\n            k_errors = np.concatenate((k_errors, tmp_k_errors))\n            k_states = np.concatenate((k_states, tmp_k_states), axis=2)\n            k_attn_scores = np.concatenate((k_attn_scores, tmp_k_attn_scores))\n\n    return_elements = []\n    if return_outputs:\n        return_elements += [k_outputs]\n    if return_states:\n        return_elements += [k_states]\n    if return_attn_scores:\n        return_elements += [k_attn_scores]\n\n    if len(return_elements) > 0:\n        return calc_metrics(k_outputs, target_seqs, char_enc, char_dec, k_errors, exact_word) + tuple(return_elements)\n\n    return calc_metrics(k_outputs, target_seqs, char_enc, char_dec, k_errors, exact_word)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:37.716418Z","iopub.execute_input":"2022-05-07T16:08:37.719236Z","iopub.status.idle":"2022-05-07T16:08:37.787995Z","shell.execute_reply.started":"2022-05-07T16:08:37.719206Z","shell.execute_reply":"2022-05-07T16:08:37.787281Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Custom class to calculate word level and charecter level validation accuracy","metadata":{}},{"cell_type":"markdown","source":"### Train Function","metadata":{}},{"cell_type":"code","source":"def train(model, train_input_data, train_target_data, val_input_data, val_target_data, beam_width = 5, attention = True,\n                batch_size = 256, optimizer = 'adam', learning_rate = 0.001, epochs = 10, loss_fn = 'categorical_crossentropy'):\n    \n    # Function to train the model using the mentioned optimizer, learning rate and epochs using given training and validation data\n\n    if optimizer == 'adam':\n        model.compile(optimizer = Adam(learning_rate=learning_rate), loss = loss_fn, metrics = ['accuracy'])\n    elif optimizer == 'momentum':\n        model.compile(optimizer = SGD(learning_rate=learning_rate, momentum = 0.9), loss = loss_fn, metrics = ['accuracy'])\n    elif optimizer == 'rmsprop':\n        model.compile(optimizer = RMSprop(learning_rate=learning_rate), loss = loss_fn, metrics = ['accuracy'])\n    elif optimizer == 'nesterov':\n        model.compile(optimizer = SGD(learning_rate=learning_rate, momentum = 0.9, nesterov = True), loss = loss_fn, metrics = ['accuracy'])\n    elif optimizer == 'nadam':\n        model.compile(optimizer = Nadam(learning_rate=learning_rate), loss = loss_fn, metrics = ['accuracy'])\n    else:\n        model.compile(optimizer = SGD(learning_rate=learning_rate), loss = loss_fn, metrics = ['accuracy'])\n\n    # Using validation accuracy as the metric\n    model.fit(train_input_data,\n              train_target_data,\n              batch_size = batch_size,\n              epochs = epochs\n             )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:38.226457Z","iopub.execute_input":"2022-05-07T16:08:38.228558Z","iopub.status.idle":"2022-05-07T16:08:38.243248Z","shell.execute_reply.started":"2022-05-07T16:08:38.228515Z","shell.execute_reply":"2022-05-07T16:08:38.242317Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Function to calculate levenshtein distance between two sequences\nCode refered from: https://codereview.stackexchange.com/questions/217065/calculate-levenshtein-distance-between-two-strings-in-python","metadata":{}},{"cell_type":"code","source":"def levenshtein_dist(s1, s2):\n    # Function to calculate levenshtein distance between two sequences usign Dynamic Programming\n    m, n = len(s1)+1, len(s2)+1\n    # Initialisation\n    dp = np.zeros((m, n))\n    # Base case\n    dp[0,1:] = np.arange(1,n)\n    dp[1:,0] = np.arange(1,m)\n\n    # Recursion\n    for i in range(1,m):\n        for j in range(1,n):\n            if s1[i-1] == s2[j-1]:\n                dp[i,j] = min(dp[i-1,j-1], dp[i-1,j]+1, dp[i,j-1]+1)\n            else:\n                dp[i,j] = min(dp[i,j-1], dp[i-1,j], dp[i-1,j-1]) + 1\n    \n    return dp[m-1,n-1]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:38.248096Z","iopub.execute_input":"2022-05-07T16:08:38.250950Z","iopub.status.idle":"2022-05-07T16:08:38.264284Z","shell.execute_reply.started":"2022-05-07T16:08:38.250905Z","shell.execute_reply":"2022-05-07T16:08:38.263363Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Test Model","metadata":{}},{"cell_type":"code","source":"def test(model, test_enc_input, test_dec_target, max_decoder_seq_length, target_char_enc, target_char_dec, test_input=None):\n    '''\n    Function to evaluate the model metrics on test data and optionally save the predictions.\n    Inputs :\n        test_enc_input -- input to encoder(numpy array shape : (None, timesteps)) (where characters are encoded as integers)\n        test_dec_target -- expected target in onehot format(numpy array shape : (None, timesteps, decoder_vocab_size))\n        max_decoder_seq_length -- number of timesteps in the decoder(int)\n        target_enc_enc -- target character encoding(dict)\n        target_char_dec -- target character decoding(list)\n        test_input -- input as words(list of string : (no_samples, input word), default : None) (needed while saving predictions to file alone)\n    Outputs :\n        acc -- character-wise match accuracy(float)\n        exact_K_acc -- exact word match accuracy using the beam width for the model(float)\n        exact_acc -- exact word match accuracy using the first prediction (float)(which is equivalent to beam width = 1)\n        loss -- loss value(float)\n        true_out -- true output(list of string : (no_samples, word))\n        pred_out -- predicted output(2D list of string : (no_samples, K, word))\n        pred_scores -- levenshtein distance of prediction to true output(2D list : (no_samples, K))\n        attn_scores -- attention scores(numpy ndarray of size : (None, K, decoder_timesteps, encoder_timesteps))\n        model -- the model obtained from the run\n    '''\n    \n\n    no_samples, K, batch_size = test_enc_input.shape[0], 5, 64\n    acc, exact_K_acc, loss, outputs, attn_scores = beam_decoder(model, test_enc_input, test_dec_target, max_decoder_seq_length, target_char_enc, \n                                                                target_char_dec, K, batch_size, True,\n                                                                return_outputs=True, return_attn_scores=True)\n    \n    print(f'Test accuracy (word level with beam width = {K}) : {exact_K_acc*100:.2f}%')\n\n    test_target = np.argmax(test_dec_target, axis=-1)\n    true_out = convert_to_word(test_target, target_char_enc, target_char_dec)\n    pred_out = [[] for _ in range(no_samples)]\n    pred_scores = [[] for _ in range(no_samples)]\n    for k in range(K):\n        pred = convert_to_word(outputs[:,k], target_char_enc, target_char_dec)\n        pred_out = [pred_out[b] + [pred[b]] for b in range(no_samples)]\n        pred_scores = [pred_scores[b] + [levenshtein_dist(pred[b], true_out[b])] for b in range(no_samples)]\n    \n    equal = [pred_out[i][0] == true_out[i] for i in range(no_samples)]\n    exact_acc = np.mean(equal)\n\n    print(f'Test accuracy (word level with the first prediction) : {exact_acc*100:.2f}%')\n    print('\\n')\n    \n\n    # We write the input and top K outputs in decreasing order of probabilities to the file\n    pred_file_name = 'predictions_attention.csv'\n    with open(pred_file_name, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Input\"] + [\"Prediction_\"+str(k+1) for k in range(K)])\n        for b in range(no_samples):\n            writer.writerow([test_input[b]] + [pred_out[b][k] for k in range(K)])\n\n\n    return acc, exact_K_acc, exact_acc, loss, true_out, pred_out, pred_scores, attn_scores, model","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:38.269819Z","iopub.execute_input":"2022-05-07T16:08:38.272146Z","iopub.status.idle":"2022-05-07T16:08:38.293976Z","shell.execute_reply.started":"2022-05-07T16:08:38.272107Z","shell.execute_reply":"2022-05-07T16:08:38.293181Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Function to print sample prediction","metadata":{}},{"cell_type":"code","source":"def get_color(value, cmap=None):\n    \n  # Function to get appropriate color for a value between 0 and 1 from the default blue to red hard-coded colors or a matplotlib cmap \n  \n  colors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n    '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n    '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n    '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n  if cmap is not None:\n      rgba = matplotlib.cm.get_cmap(cmap)(value)\n      return 'rgb'+str(tuple([int(c*255) for c in rgba[:-1]]))\n  value = min(int((value * 100) / 5), 19)\n  return colors[value]\n\ndef visualize_samples(input, true_out, pred_out, pred_scores, rand_seq=None):\n    \n    '''\n    Function to print sample outputs in a neat format\n    Arguments :\n        input -- input words\n        true_out -- true output as words\n        pred_out -- K predicted output words\n        pred_scores -- levenshtein distance for the predictions to the true output\n        rand_seq -- list of indices from the dataset passed for which the sample outputs are to be printed (If None, random 10 samples will be chosen)\n    Returns :\n        rand_seq -- the list of indices for which sample outputs are printed\n    '''\n    \n    n_samples = len(true_out)\n    if rand_seq is None:\n        rand_seq = np.random.randint(n_samples, size=(10,))\n    print('-'*20 + f' Top {len(pred_scores[0])} predictions in decreasing order of probabilities for 10 random samples ' + '-'*20)\n    print('')\n    for i in rand_seq:\n        K = len(pred_scores[i])\n        html_str = '''\n        <table style=\"border:2px solid black; border-collapse:collapse\">\n        <caption> <strong>INPUT :</strong> {} &emsp; | &emsp; <strong> TRUE OUTPUT : </strong> {} </caption>\n        <tr>\n        <th scope=\"row\" style=\"border:1px solid black;padding:10px;text-align:left\"> Top {} Predictions </th>\n        '''.format(input[i], true_out[i], K)\n        for k in range(K):\n            html_str += '''\n            <td style=\"color:#000;background-color:{};border:1px solid black;padding:10px\"> {} </td>\n            '''.format(get_color(pred_scores[i][k]/5), pred_out[i][k])\n        html_str += '''\n        </tr>\n        <tr>\n        <th scope=\"row\" style=\"border:1px solid black;padding:10px;text-align:left\"> Levenshtein distance (to true output) &emsp; </th>\n        '''\n        for k in range(K):\n            html_str += '''\n            <td style=\"border:1px solid black;padding:10px\"> {} </td>\n            '''.format(pred_scores[i][k])\n        html_str += '''\n        </tr>\n        </table>\n        '''\n        p = display(html_print(html_str))\n        print('\\n\\n')\n    \n    return rand_seq","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:38.299159Z","iopub.execute_input":"2022-05-07T16:08:38.302535Z","iopub.status.idle":"2022-05-07T16:08:38.333657Z","shell.execute_reply.started":"2022-05-07T16:08:38.302418Z","shell.execute_reply":"2022-05-07T16:08:38.332628Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Testing with the best model","metadata":{}},{"cell_type":"code","source":"#Building the model with the best hyperparameters\nmodel = build_model(len(input_char_dec), len(target_char_dec), \n                    inp_emb_size=512, n_enc_layers=2, \n                    n_dec_layers=5, h_layer_size=256, \n                    cell_type='LSTM', dropout=0.3, r_dropout=0.3)\n\n\n#Training the model with best set of hyperparameters\nmodel = train(model = model, train_input_data= [train_enc_x,train_dec_x], train_target_data= train_dec_y, \n                      val_input_data= [val_enc_x,val_dec_x], val_target_data= val_dec_y, beam_width= 5,\n                      attention = True, batch_size= 128, optimizer = 'adam', learning_rate= 0.001, \n                      epochs= 15)\nmodel.save(\"best_model_attn.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:08:38.338581Z","iopub.execute_input":"2022-05-07T16:08:38.341427Z","iopub.status.idle":"2022-05-07T17:11:12.585689Z","shell.execute_reply.started":"2022-05-07T16:08:38.341392Z","shell.execute_reply":"2022-05-07T17:11:12.584944Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Testing the model with best set of hyperparameters\n\ntest_acc, test_exact_K_acc, test_exact_acc, test_loss, test_true_out,\\\ntest_pred_out, test_pred_scores,attn_scores, model = test(model, test_enc_x, \n                                                          test_dec_y, max_decoder_seq_length, \n                                                          target_char_enc, \n                                                          target_char_dec, test_x)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:11:12.586952Z","iopub.execute_input":"2022-05-07T17:11:12.587695Z","iopub.status.idle":"2022-05-07T17:19:16.471668Z","shell.execute_reply.started":"2022-05-07T17:11:12.587655Z","shell.execute_reply":"2022-05-07T17:19:16.470917Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing random samples of predictions","metadata":{}},{"cell_type":"code","source":"random_samples = visualize_samples(test_x, test_true_out, test_pred_out, test_pred_scores)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:19:16.473346Z","iopub.execute_input":"2022-05-07T17:19:16.473620Z","iopub.status.idle":"2022-05-07T17:19:16.505577Z","shell.execute_reply.started":"2022-05-07T17:19:16.473584Z","shell.execute_reply":"2022-05-07T17:19:16.504928Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Visualise the best model (with attention)","metadata":{}},{"cell_type":"code","source":"plot_model(model, to_file=\"model_attn.png\", show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:19:16.506777Z","iopub.execute_input":"2022-05-07T17:19:16.507538Z","iopub.status.idle":"2022-05-07T17:19:17.445609Z","shell.execute_reply.started":"2022-05-07T17:19:16.507500Z","shell.execute_reply":"2022-05-07T17:19:17.444856Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Function to Plot attention heatmaps","metadata":{}},{"cell_type":"code","source":"!pip install wget\nimport wget\nfrom zipfile import ZipFile","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:19:17.446970Z","iopub.execute_input":"2022-05-07T17:19:17.447251Z","iopub.status.idle":"2022-05-07T17:19:29.983354Z","shell.execute_reply.started":"2022-05-07T17:19:17.447214Z","shell.execute_reply":"2022-05-07T17:19:29.982411Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Downloading Bengali fonts for visualization purpose","metadata":{}},{"cell_type":"code","source":"filename = 'Hind_Siliguri'\nurl = 'https://fonts.google.com/download?family=Hind%20Siliguri'\n\nfilename_zip = wget.download(url)\nfilename_zip = filename+'.zip'\nwith ZipFile(filename_zip, 'r') as z:\n    z.printdir()\n    print('\\Extracting files....')\n    z.extractall()\n    print('Done')\nos.remove(filename_zip)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:19:29.984967Z","iopub.execute_input":"2022-05-07T17:19:29.985270Z","iopub.status.idle":"2022-05-07T17:19:30.680740Z","shell.execute_reply.started":"2022-05-07T17:19:29.985232Z","shell.execute_reply":"2022-05-07T17:19:30.679370Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def plot_attn_heatmaps(input, pred_out, pred_scores, attn_scores, wandb_log=False, rand_seq=None):\n    \n    '''\n    Function to plot attention heatmaps\n    Arguments :\n        input -- input words\n        true_out -- true output as words\n        pred_out -- K predicted output words\n        pred_scores -- levenshtein distance for the predictions to the true output\n        attn_scores -- attention scores\n        wandb_log -- whether or not to log the image generated to WANDB(bool, default : False)\n        rand_seq -- list of indices from the dataset passed for which the sample outputs are to be printed (If None, random 9 samples will be chosen)\n    Returns :\n        rand_seq -- the list of indices for which sample outputs are printed\n    '''\n    \n    no_samples = len(pred_out)\n    if rand_seq is None:\n        rand_seq = np.random.randint(no_samples, size=(9,))\n    rand_seq = rand_seq[:9]\n    \n    plt.close('all')\n    fig = plt.figure(figsize=(15,15))\n    fig, axes = plt.subplots(3, 3, figsize=(15, 15), constrained_layout=True)\n    plt.suptitle('Attention Heatmaps', fontsize='x-large')\n    for i,ax in zip(rand_seq, axes.flat):\n        K = len(pred_scores[i])\n        k = np.argmin(pred_scores[i])\n        im = ax.imshow(attn_scores[i,k,:len(pred_out[i][k])+1,:len(input[i])+1].T, vmin=0, vmax=1, cmap='magma')\n        ax.set_xticks(range(len(pred_out[i][k])+1))\n        ax.set_xticklabels(list(pred_out[i][k])+['<end>'], fontproperties=FontProperties(fname=\"./HindSiliguri-Regular.ttf\"))\n        ax.set_yticks(range(len(input[i])+1))\n        ax.set_yticklabels(list(input[i])+['<end>'])\n        ax.set_ylabel(u'Encoder Input')\n        ax.set_xlabel(f'Decoder Output')\n        ax.set_title(str(i) + r'$^{th}$ example of Test Set')\n        ax.set_aspect(\"equal\")\n        ax.grid(False)\n\n    # create colorbar\n    fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.7)\n    \n    # Log in WANDB\n    if wandb_log:\n        run = wandb.init(project=\"Seq2SeqLearning\", entity=\"cs21s048-cs21s058\", reinit=True)\n        wandb.log({'attention_heatmaps': fig})\n        run.finish()\n\n    plt.savefig('attention_heatmaps.png')\n    plt.show()\n\n    return rand_seq","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:19:30.682127Z","iopub.execute_input":"2022-05-07T17:19:30.682364Z","iopub.status.idle":"2022-05-07T17:19:30.695520Z","shell.execute_reply.started":"2022-05-07T17:19:30.682330Z","shell.execute_reply":"2022-05-07T17:19:30.694517Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"plot_attn_heatmaps(test_x, test_pred_out, test_pred_scores, attn_scores, False, random_samples)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:19:30.696829Z","iopub.execute_input":"2022-05-07T17:19:30.697253Z","iopub.status.idle":"2022-05-07T17:19:33.913142Z","shell.execute_reply.started":"2022-05-07T17:19:30.697218Z","shell.execute_reply":"2022-05-07T17:19:33.912338Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Attention Connections","metadata":{}},{"cell_type":"code","source":"def cstr(s, color=None):\n  # Function to get text html element\n  if color is None:\n      return '''<text style=\"padding:2px; color:#C0C0C0\"> {} </text>'''.format(s)\n  return '''<text style=\"color:#000;background-color:{}; padding:2px; color:#FF6699\"> {} </text>'''.format(color, s)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:19:33.914805Z","iopub.execute_input":"2022-05-07T17:19:33.915374Z","iopub.status.idle":"2022-05-07T17:19:33.920629Z","shell.execute_reply.started":"2022-05-07T17:19:33.915335Z","shell.execute_reply":"2022-05-07T17:19:33.919979Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def print_connectivity(input, pred_out, pred_scores, attn_scores, dec_char_ind=0):\n    '''\n    Function to visualize attention for one index of decoder output of one sample\n    Inputs :\n        input -- sample input word\n        pred_out -- K predicted output words for the sample\n        pred_scores -- levenshtein distance for the predictions to the true output\n        attn_scores -- attention scores\n        dec_char_ind -- index of the character in decoder for which the visuzalization is to be done\n    Outputs :\n        -- None --\n    '''\n    K = len(pred_scores)\n    print('-'*20 + f' Visualizing attention for Top {K} predictions (in decreasing order of probabilities) ' + '-'*20)\n    print('')\n    html_str = '''\n    <table style=\"border:2px solid black; border-collapse:collapse; font-size:1.5em\">\n    <caption> <strong>INPUT : </strong> {} </caption>\n    <tr>\n    <th style=\"border:1px solid black;padding:10px;text-align:center\"> Character in Prediction Focussed </th>\n    <th style=\"border:1px solid black;padding:10px;text-align:center\"> Attention Visualization </th>\n    </tr>\n    '''.format(input)\n    for k in range(K):  \n        char = pred_out[k][dec_char_ind] if dec_char_ind < len(pred_out[k]) else '&lt end &gt' if dec_char_ind == len(pred_out[k]) else '&lt blank &gt'\n        middle_char = pred_out[k][dec_char_ind] if dec_char_ind < len(pred_out[k]) else ''\n        end_str = pred_out[k][dec_char_ind+1:] if dec_char_ind < len(pred_out[k])-1 else ''\n        html_str += '''\n        <tr>\n        <td style=\"border:1px solid black;padding:10px;text-align:center\"> character at index {} of {}<span style=\"color: #FF1493\">{}</span>{} <br/> ({}) </td>\n        <td style=\"border:1px solid black;padding:10px;text-align:center\">\n        '''.format(dec_char_ind, pred_out[k][:dec_char_ind], middle_char, end_str, char)\n        for i,c in enumerate(input):\n            html_str += '''\n            {}\n            '''.format(cstr(c, get_color(attn_scores[k,dec_char_ind,i], 'YlGnBu')))\n        html_str += '''\n        </td>\n        </tr>\n        '''\n    html_str += '''\n    </table>\n    '''\n    display(html_print(html_str))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:19:33.921779Z","iopub.execute_input":"2022-05-07T17:19:33.922226Z","iopub.status.idle":"2022-05-07T17:19:33.933039Z","shell.execute_reply.started":"2022-05-07T17:19:33.922189Z","shell.execute_reply":"2022-05-07T17:19:33.932310Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def visualize_attention(sample_ind=0, dec_char_ind=0):\n    \n    \n    # Function to visualize the importance of encoder input characters to the (dec_char_ind)th character of the output,\n    # for the (sample_ind)th sample in the test data\n    \n    \n    print_connectivity(test_x[sample_ind], test_pred_out[sample_ind], test_pred_scores[sample_ind], attn_scores[sample_ind], dec_char_ind)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:19:33.937126Z","iopub.execute_input":"2022-05-07T17:19:33.937315Z","iopub.status.idle":"2022-05-07T17:19:33.945280Z","shell.execute_reply.started":"2022-05-07T17:19:33.937293Z","shell.execute_reply":"2022-05-07T17:19:33.944568Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nimport ipywidgets as widgets\nfrom ipywidgets import interact, Layout, IntSlider\n\n'''One can directly use visualize_attention(sample_ind, decoder_index) to get the result if interaction isn't needed, \nbut uncommenting below code is easier to use and offers a good way to choose the sample index and decoder index, and seeing the attention for K decoder predictons'''\n\n\n@interact(sample_ind = IntSlider(min=0, max=len(test_x)-1, step=1, value=10, layout=Layout(width='800px')))\ndef f(sample_ind):\n    print(f'Input : {test_x[sample_ind]}')\n    print(f'Top {len(test_pred_out[sample_ind])} predictions : ')\n    mx_len = 0\n    for pred in test_pred_out[sample_ind]:\n        print(pred)\n        mx_len = max(mx_len, len(pred))\n    \n    @interact(character_ind = widgets.IntSlider(min=0, max=mx_len-1, step=1, value=0))\n    def g(character_ind):\n        visualize_attention(sample_ind, character_ind)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:19:33.946325Z","iopub.execute_input":"2022-05-07T17:19:33.946684Z","iopub.status.idle":"2022-05-07T17:19:34.111652Z","shell.execute_reply.started":"2022-05-07T17:19:33.946647Z","shell.execute_reply":"2022-05-07T17:19:34.110880Z"},"trusted":true},"execution_count":29,"outputs":[]}]}